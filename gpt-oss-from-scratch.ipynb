{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236d9b87",
   "metadata": {
    "papermill": {
     "duration": 0.006804,
     "end_time": "2025-09-24T06:13:20.878994",
     "exception": false,
     "start_time": "2025-09-24T06:13:20.872190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GPT-OSS-mini: GPT-OSS Implementation from Scratch\n",
    "\n",
    "A GPT model implementation incorporating state-of-the-art techniques from modern language model research.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Rotary Position Embedding (RoPE)**: Superior positional encoding\n",
    "- **Grouped Query Attention (GQA)**: Memory-efficient attention mechanism  \n",
    "- **Mixture of Experts (MoE)**: Sparse routing for scalable capacity\n",
    "- **SwiGLU Activation**: Advanced activation functions\n",
    "- **RMS Normalization**: Efficient alternative to LayerNorm\n",
    "- **Complete Training Pipeline**: Modern optimization and monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ec607",
   "metadata": {
    "papermill": {
     "duration": 0.005141,
     "end_time": "2025-09-24T06:13:20.889749",
     "exception": false,
     "start_time": "2025-09-24T06:13:20.884608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's install and import all the required libraries. Each library serves a specific purpose in our implementation:\n",
    "\n",
    "- **torch**: Core deep learning framework for building neural networks\n",
    "- **tiktoken**: OpenAI's fast tokenizer for text processing\n",
    "- **matplotlib**: Visualization library for plotting training metrics\n",
    "- **numpy**: Numerical computing (required by matplotlib)\n",
    "- **requests**: HTTP library for downloading data from Wikipedia API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fe49b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:13:20.901319Z",
     "iopub.status.busy": "2025-09-24T06:13:20.901093Z",
     "iopub.status.idle": "2025-09-24T06:14:39.995037Z",
     "shell.execute_reply": "2025-09-24T06:14:39.994259Z"
    },
    "papermill": {
     "duration": 79.101288,
     "end_time": "2025-09-24T06:14:39.996444",
     "exception": false,
     "start_time": "2025-09-24T06:13:20.895156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n",
      "Collecting tiktoken==0.11.0\r\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.11.0) (2024.11.6)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.11.0) (2.32.4)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.11.0) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.11.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.11.0) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.11.0) (2025.6.15)\r\n",
      "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tiktoken\r\n",
      "  Attempting uninstall: tiktoken\r\n",
      "    Found existing installation: tiktoken 0.9.0\r\n",
      "    Uninstalling tiktoken-0.9.0:\r\n",
      "      Successfully uninstalled tiktoken-0.9.0\r\n",
      "Successfully installed tiktoken-0.11.0\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.4)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\r\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if running for the first time)\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install tiktoken==0.11.0\n",
    "!pip install matplotlib\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b41685f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:40.044470Z",
     "iopub.status.busy": "2025-09-24T06:14:40.043916Z",
     "iopub.status.idle": "2025-09-24T06:14:43.285921Z",
     "shell.execute_reply": "2025-09-24T06:14:43.285092Z"
    },
    "papermill": {
     "duration": 3.266824,
     "end_time": "2025-09-24T06:14:43.287026",
     "exception": false,
     "start_time": "2025-09-24T06:14:40.020202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import all necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tiktoken\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Apple devices\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609291b",
   "metadata": {
    "papermill": {
     "duration": 0.023294,
     "end_time": "2025-09-24T06:14:43.334019",
     "exception": false,
     "start_time": "2025-09-24T06:14:43.310725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Data Acquisition and Preprocessing\n",
    "\n",
    "We'll use Wikipedia as our training data source. The Wikipedia API allows us to fetch clean text data that's perfect for language model training. We'll download the \"Python (programming language)\" page as our training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202a8beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:43.382075Z",
     "iopub.status.busy": "2025-09-24T06:14:43.381698Z",
     "iopub.status.idle": "2025-09-24T06:14:43.646628Z",
     "shell.execute_reply": "2025-09-24T06:14:43.645776Z"
    },
    "papermill": {
     "duration": 0.290746,
     "end_time": "2025-09-24T06:14:43.647750",
     "exception": false,
     "start_time": "2025-09-24T06:14:43.357004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Wikipedia page: Python (programming language)\n",
      "Successfully downloaded 46,349 characters\n",
      "Saved to: python_wikipedia.txt\n",
      "\n",
      "Dataset Statistics:\n",
      "   Total characters: 46,349\n",
      "   Total words (approx): 7,050\n",
      "   Total lines: 337\n",
      "\n",
      "Text Preview (first 500 characters):\n",
      "============================================================\n",
      "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\n",
      "Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\n",
      "Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a major revi...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def download_wikipedia_page(page_title: str, save_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Download a Wikipedia page using the Wikipedia API.\n",
    "    \n",
    "    Args:\n",
    "        page_title: Title of the Wikipedia page to download\n",
    "        save_filename: Filename to save the downloaded text\n",
    "    \n",
    "    Returns:\n",
    "        Downloaded text content\n",
    "    \"\"\"\n",
    "    # Wikipedia API endpoint\n",
    "    API_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    # API parameters for fetching plain text\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\", \n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,  # Return plain text instead of HTML\n",
    "        \"titles\": page_title\n",
    "    }\n",
    "    \n",
    "    # Set a proper user-agent (required by Wikipedia)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"GPT-Model-Tutorial/1.0 (Educational Purpose)\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Downloading Wikipedia page: {page_title}\")\n",
    "    \n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(API_URL, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract the page text\n",
    "        page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "        text_content = page.get(\"extract\", \"\")\n",
    "        \n",
    "        # Save to file\n",
    "        with open(save_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text_content)\n",
    "        \n",
    "        print(f\"Successfully downloaded {len(text_content):,} characters\")\n",
    "        print(f\"Saved to: {save_filename}\")\n",
    "        \n",
    "        return text_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading page: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Download the Python programming language page\n",
    "page_title = \"Python (programming language)\" \n",
    "filename = \"python_wikipedia.txt\"\n",
    "raw_text = download_wikipedia_page(page_title, filename)\n",
    "\n",
    "# Display some basic statistics about our dataset\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"   Total characters: {len(raw_text):,}\")\n",
    "print(f\"   Total words (approx): {len(raw_text.split()):,}\")\n",
    "print(f\"   Total lines: {len(raw_text.splitlines()):,}\")\n",
    "\n",
    "# Show a preview of the text\n",
    "print(f\"\\nText Preview (first 500 characters):\")\n",
    "print(\"=\" * 60)\n",
    "print(raw_text[:500] + \"...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff19b3",
   "metadata": {
    "papermill": {
     "duration": 0.022946,
     "end_time": "2025-09-24T06:14:43.694322",
     "exception": false,
     "start_time": "2025-09-24T06:14:43.671376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Tokenization Implementation\n",
    "\n",
    "Tokenization is the process of converting text into numerical tokens that our model can understand. We'll use OpenAI's `tiktoken` library with the `o200k_harmony` encoding, which is used in GPT-4 and other modern models.\n",
    "\n",
    "### Why tiktoken?\n",
    "- **Fast**: Written in Rust, much faster than traditional tokenizers\n",
    "- **Modern**: Uses the same tokenization as GPT-4\n",
    "- **Large vocabulary**: ~200k tokens for better text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba53c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:43.786231Z",
     "iopub.status.busy": "2025-09-24T06:14:43.785957Z",
     "iopub.status.idle": "2025-09-24T06:14:45.180668Z",
     "shell.execute_reply": "2025-09-24T06:14:45.179869Z"
    },
    "papermill": {
     "duration": 1.464519,
     "end_time": "2025-09-24T06:14:45.181929",
     "exception": false,
     "start_time": "2025-09-24T06:14:43.717410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Information:\n",
      "   Vocabulary size: 201,088 tokens\n",
      "   Encoding name: o200k_harmony\n",
      "\n",
      "Tokenization Examples:\n",
      "================================================================================\n",
      "\n",
      "1. Original text: 'Hello, world!'\n",
      "   Token IDs: [13225, 11, 2375, 0]\n",
      "   Number of tokens: 4\n",
      "   Decoded text: 'Hello, world!'\n",
      "   Matches original: True\n",
      "\n",
      "2. Original text: 'The quick brown fox jumps over the lazy dog.'\n",
      "   Token IDs: [976, 4853, 19705, 68347, 65613, 1072, 290, 29082, 6446, 13]\n",
      "   Number of tokens: 10\n",
      "   Decoded text: 'The quick brown fox jumps over the lazy dog.'\n",
      "   Matches original: True\n",
      "\n",
      "3. Original text: 'Python is a high-level programming language.'\n",
      "   Token IDs: [60502, 382, 261, 1932, 19231, 23238, 6439, 13]\n",
      "   Number of tokens: 8\n",
      "   Decoded text: 'Python is a high-level programming language.'\n",
      "   Matches original: True\n",
      "\n",
      "4. Original text: 'Modern AI models use transformers!'\n",
      "   Token IDs: [59679, 20837, 7015, 1199, 152728, 0]\n",
      "   Number of tokens: 6\n",
      "   Decoded text: 'Modern AI models use transformers!'\n",
      "   Matches original: True\n",
      "\n",
      "Wikipedia Sample Tokenization:\n",
      "   Sample text: 'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\n",
      "Python is dynamically type-checked and garbage-'\n",
      "   Number of tokens: 33\n",
      "   Compression ratio: 6.06 chars/token\n",
      "\n",
      "Tokenization setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer with GPT-4's encoding\n",
    "tokenizer = tiktoken.get_encoding(\"o200k_harmony\")\n",
    "\n",
    "# Get vocabulary information\n",
    "vocab_size = tokenizer.max_token_value + 1\n",
    "\n",
    "print(f\"Tokenizer Information:\")\n",
    "print(f\"   Vocabulary size: {vocab_size:,} tokens\")\n",
    "print(f\"   Encoding name: o200k_harmony\")\n",
    "\n",
    "# Demonstrate tokenization with examples\n",
    "test_examples = [\n",
    "    \"Hello, world!\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Python is a high-level programming language.\",\n",
    "    \"Modern AI models use transformers!\"\n",
    "]\n",
    "\n",
    "print(f\"\\nTokenization Examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, text in enumerate(test_examples, 1):\n",
    "    # Encode text to token IDs\n",
    "    token_ids = tokenizer.encode(text)\n",
    "    \n",
    "    # Decode back to text (should be identical)\n",
    "    decoded_text = tokenizer.decode(token_ids)\n",
    "    \n",
    "    print(f\"\\n{i}. Original text: '{text}'\")\n",
    "    print(f\"   Token IDs: {token_ids}\")\n",
    "    print(f\"   Number of tokens: {len(token_ids)}\")\n",
    "    print(f\"   Decoded text: '{decoded_text}'\")\n",
    "    print(f\"   Matches original: {text == decoded_text}\")\n",
    "\n",
    "# Test with our Wikipedia data\n",
    "sample_text = raw_text[:200]  # First 200 characters\n",
    "sample_tokens = tokenizer.encode(sample_text)\n",
    "\n",
    "print(f\"\\nWikipedia Sample Tokenization:\")\n",
    "print(f\"   Sample text: '{sample_text}'\")\n",
    "print(f\"   Number of tokens: {len(sample_tokens)}\")\n",
    "print(f\"   Compression ratio: {len(sample_text)/len(sample_tokens):.2f} chars/token\")\n",
    "\n",
    "# Helper functions for text/token conversion\n",
    "def text_to_tokens(text: str) -> torch.Tensor:\n",
    "    \"\"\"Convert text to token tensor.\"\"\"\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "def tokens_to_text(tokens: torch.Tensor) -> str:\n",
    "    \"\"\"Convert token tensor back to text.\"\"\"\n",
    "    flat_tokens = tokens.squeeze(0) if tokens.dim() > 1 else tokens\n",
    "    return tokenizer.decode(flat_tokens.tolist())\n",
    "\n",
    "print(f\"\\nTokenization setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c1f90",
   "metadata": {
    "papermill": {
     "duration": 0.023231,
     "end_time": "2025-09-24T06:14:45.230241",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.207010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Dataset and DataLoader Creation\n",
    "\n",
    "Now we'll create a custom PyTorch Dataset class that prepares our text data for training. We use a sliding window approach where each training example consists of a sequence of tokens and the target is the same sequence shifted by one position.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Sliding Window**: Extract overlapping sequences from our text\n",
    "- **Stride**: How much we move the window each time (smaller = more data, more overlap)\n",
    "- **Context Length**: Maximum sequence length our model can handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b7617f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:45.277953Z",
     "iopub.status.busy": "2025-09-24T06:14:45.277298Z",
     "iopub.status.idle": "2025-09-24T06:14:45.300905Z",
     "shell.execute_reply": "2025-09-24T06:14:45.299998Z"
    },
    "papermill": {
     "duration": 0.048851,
     "end_time": "2025-09-24T06:14:45.302138",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.253287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset creation...\n",
      "Tokenizing text...\n",
      "Tokenized 5,000 characters into 1,025 tokens\n",
      "Creating sliding windows...\n",
      "Created 31 training sequences\n",
      "\n",
      "Sample Training Examples:\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Input:  'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code ...'\n",
      "Target: ' is a high-level, general-purpose programming language. Its design philosophy emphasizes code readab...'\n",
      "\n",
      "Example 2:\n",
      "Input:  '-collected. It supports multiple programming paradigms, including structured (particularly procedura...'\n",
      "Target: 'lected. It supports multiple programming paradigms, including structured (particularly procedural), ...'\n",
      "\n",
      "Example 3:\n",
      "Input:  ' the late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a ...'\n",
      "Target: ' late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a majo...'\n",
      "Dataset testing complete!\n"
     ]
    }
   ],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for GPT training with sliding window approach.\n",
    "    \n",
    "    The dataset creates input-target pairs where:\n",
    "    - Input: sequence of tokens [t1, t2, t3, ..., tn]\n",
    "    - Target: same sequence shifted by 1 [t2, t3, t4, ..., tn+1]\n",
    "    \n",
    "    This allows the model to learn to predict the next token.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text: str, tokenizer, max_length: int = 128, stride: int = 64):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            text: Raw text to create dataset from\n",
    "            tokenizer: Tokenizer to encode text\n",
    "            max_length: Maximum sequence length\n",
    "            stride: Step size for sliding window\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Tokenize the entire text\n",
    "        print(f\"Tokenizing text...\")\n",
    "        self.token_ids = tokenizer.encode(text)\n",
    "        print(f\"Tokenized {len(text):,} characters into {len(self.token_ids):,} tokens\")\n",
    "        \n",
    "        # Create sliding windows\n",
    "        self.input_sequences = []\n",
    "        self.target_sequences = []\n",
    "        \n",
    "        print(f\"Creating sliding windows...\")\n",
    "        for i in range(0, len(self.token_ids) - max_length, stride):\n",
    "            input_seq = self.token_ids[i:i + max_length]\n",
    "            target_seq = self.token_ids[i + 1:i + max_length + 1]\n",
    "            \n",
    "            self.input_sequences.append(torch.tensor(input_seq, dtype=torch.long))\n",
    "            self.target_sequences.append(torch.tensor(target_seq, dtype=torch.long))\n",
    "        \n",
    "        print(f\"Created {len(self.input_sequences):,} training sequences\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_sequences[idx], self.target_sequences[idx]\n",
    "    \n",
    "    def get_sample_text(self, idx: int = 0) -> tuple:\n",
    "        \"\"\"Get a sample input-target pair as readable text.\"\"\"\n",
    "        input_seq, target_seq = self[idx]\n",
    "        input_text = self.tokenizer.decode(input_seq.tolist())\n",
    "        target_text = self.tokenizer.decode(target_seq.tolist())\n",
    "        return input_text, target_text\n",
    "\n",
    "\n",
    "def create_dataloader(text: str, batch_size: int = 4, max_length: int = 128, \n",
    "                     stride: int = 64, shuffle: bool = True, num_workers: int = 0) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Create a DataLoader for GPT training.\n",
    "    \n",
    "    Args:\n",
    "        text: Raw text for training\n",
    "        batch_size: Number of sequences per batch\n",
    "        max_length: Maximum sequence length\n",
    "        stride: Sliding window stride\n",
    "        shuffle: Whether to shuffle the data\n",
    "        num_workers: Number of worker processes for data loading\n",
    "    \n",
    "    Returns:\n",
    "        PyTorch DataLoader\n",
    "    \"\"\"\n",
    "    dataset = GPTDataset(text, tokenizer, max_length, stride)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),  # Speed up GPU transfer\n",
    "        drop_last=True  # Drop last incomplete batch\n",
    "    )\n",
    "    \n",
    "    print(f\"DataLoader created:\")\n",
    "    print(f\"   Batch size: {batch_size}\")\n",
    "    print(f\"   Sequence length: {max_length}\")\n",
    "    print(f\"   Number of batches: {len(dataloader)}\")\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "# Test the dataset with a small sample\n",
    "print(\"Testing dataset creation...\")\n",
    "test_text = raw_text[:5000]  # Use first 5000 characters for testing\n",
    "\n",
    "# Create a sample dataset\n",
    "sample_dataset = GPTDataset(test_text, tokenizer, max_length=64, stride=32)\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nSample Training Examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(min(3, len(sample_dataset))):\n",
    "    input_text, target_text = sample_dataset.get_sample_text(i)\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Input:  '{input_text[:100]}...'\")\n",
    "    print(f\"Target: '{target_text[:100]}...'\")\n",
    "\n",
    "print(\"Dataset testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b20d1d",
   "metadata": {
    "papermill": {
     "duration": 0.022824,
     "end_time": "2025-09-24T06:14:45.348510",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.325686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Rotary Position Embedding (RoPE)\n",
    "\n",
    "RoPE encodes position information by rotating query and key vectors in attention, enabling better relative position understanding and length extrapolation.\n",
    "\n",
    "### How it works:\n",
    "Instead of adding position embeddings to tokens, RoPE rotates the query and key vectors by an angle proportional to their position. This creates a natural way for the model to understand relative distances between tokens.\n",
    "\n",
    "**Simple Example:**\n",
    "```python\n",
    "# Traditional: position added to embedding\n",
    "token_embedding + position_embedding\n",
    "\n",
    "# RoPE: rotation applied to Q and K vectors\n",
    "q_rotated = rotate(q, position_angle)\n",
    "k_rotated = rotate(k, position_angle)\n",
    "```\n",
    "\n",
    "**Why it's important:**\n",
    "- **Relative Awareness**: The model naturally learns \"token A is 3 positions before token B\"\n",
    "- **Length Extrapolation**: Can handle sequences longer than training length\n",
    "- **No Extra Parameters**: Uses mathematical rotation instead of learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c986a247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:45.395624Z",
     "iopub.status.busy": "2025-09-24T06:14:45.395403Z",
     "iopub.status.idle": "2025-09-24T06:14:45.478583Z",
     "shell.execute_reply": "2025-09-24T06:14:45.477798Z"
    },
    "papermill": {
     "duration": 0.108126,
     "end_time": "2025-09-24T06:14:45.479736",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.371610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RoPE Implementation...\n",
      "RoPE test passed: torch.Size([2, 16, 128]) -> torch.Size([2, 16, 128])\n",
      "Magnitude preserved (diff: 0.000001)\n",
      "RoPE implementation complete!\n"
     ]
    }
   ],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Rotary Position Embedding (RoPE) implementation.\n",
    "    \n",
    "    RoPE encodes positional information by rotating query and key vectors\n",
    "    in the attention mechanism. This allows the model to understand\n",
    "    relative positions between tokens naturally.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, max_seq_len: int = 2048, base: float = 10000.0):\n",
    "        \"\"\"\n",
    "        Initialize RoPE.\n",
    "        \n",
    "        Args:\n",
    "            d_model: Model dimension (must be even)\n",
    "            max_seq_len: Maximum sequence length to support\n",
    "            base: Base for frequency calculation (10000 is standard)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        if d_model % 2 != 0:\n",
    "            raise ValueError(f\"Model dimension must be even, got {d_model}\")\n",
    "            \n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.base = base\n",
    "        \n",
    "        # Calculate inverse frequencies for each dimension pair\n",
    "        # inv_freq = 1 / (base^(2i/d_model)) for i in [0, 1, 2, ..., d_model/2-1]\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, d_model, 2).float() / d_model))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "        \n",
    "        # Pre-compute positional encodings for efficiency\n",
    "        self._build_cache(max_seq_len)\n",
    "        \n",
    "    def _build_cache(self, seq_len: int):\n",
    "        \"\"\"Pre-compute rotary embeddings for given sequence length.\"\"\"\n",
    "        # Create position indices [0, 1, 2, ..., seq_len-1]\n",
    "        positions = torch.arange(seq_len, dtype=torch.float32)\n",
    "        \n",
    "        # Calculate frequencies: positions[i] * inv_freq[j] for all i,j\n",
    "        freqs = torch.outer(positions, self.inv_freq)  # Shape: (seq_len, d_model//2)\n",
    "        \n",
    "        # Duplicate frequencies to match full dimension\n",
    "        freqs = torch.cat([freqs, freqs], dim=-1)  # Shape: (seq_len, d_model)\n",
    "        \n",
    "        # Pre-compute cos and sin for efficiency\n",
    "        cos_cached = torch.cos(freqs)\n",
    "        sin_cached = torch.sin(freqs)\n",
    "        \n",
    "        self.register_buffer('cos_cached', cos_cached)\n",
    "        self.register_buffer('sin_cached', sin_cached)\n",
    "    \n",
    "    def rotate_half(self, x):\n",
    "        \"\"\"Rotate half the dimensions of the input tensor.\"\"\"\n",
    "        # Split the last dimension into two halves\n",
    "        x1, x2 = torch.chunk(x, 2, dim=-1)\n",
    "        # Rotate: [x1, x2] -> [-x2, x1]\n",
    "        return torch.cat([-x2, x1], dim=-1)\n",
    "    \n",
    "    def forward(self, x, position_ids=None):\n",
    "        \"\"\"\n",
    "        Apply rotary position embedding to input tensor.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (..., seq_len, d_model)\n",
    "            position_ids: Optional position indices (default: 0, 1, 2, ...)\n",
    "        \n",
    "        Returns:\n",
    "            Tensor with rotary position embeddings applied\n",
    "        \"\"\"\n",
    "        *batch_dims, seq_len, d_model = x.shape\n",
    "        \n",
    "        if d_model != self.d_model:\n",
    "            raise ValueError(f\"Input dimension {d_model} doesn't match model dimension {self.d_model}\")\n",
    "        \n",
    "        # Extend cache if needed\n",
    "        if seq_len > self.cos_cached.shape[0]:\n",
    "            self._build_cache(seq_len)\n",
    "        \n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_len, device=x.device)\n",
    "        \n",
    "        # Get cos and sin for the required positions\n",
    "        cos = self.cos_cached[position_ids]  # Shape: (seq_len, d_model)\n",
    "        sin = self.sin_cached[position_ids]  # Shape: (seq_len, d_model)\n",
    "        \n",
    "        # Expand dimensions to match input tensor\n",
    "        for _ in range(len(batch_dims)):\n",
    "            cos = cos.unsqueeze(0)\n",
    "            sin = sin.unsqueeze(0)\n",
    "        \n",
    "        # Apply rotation: x_rotated = x * cos + rotate_half(x) * sin\n",
    "        x_rotated = x * cos + self.rotate_half(x) * sin\n",
    "        \n",
    "        return x_rotated\n",
    "\n",
    "# Test RoPE implementation\n",
    "print(\"Testing RoPE Implementation...\")\n",
    "rope = RotaryPositionalEmbedding(d_model=128, max_seq_len=256)\n",
    "test_input = torch.randn(2, 16, 128)\n",
    "output = rope(test_input)\n",
    "print(f\"RoPE test passed: {test_input.shape} -> {output.shape}\")\n",
    "magnitude_diff = (test_input.norm(dim=-1) - output.norm(dim=-1)).abs().max()\n",
    "print(f\"Magnitude preserved (diff: {magnitude_diff.item():.6f})\")\n",
    "print(\"RoPE implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a36c16",
   "metadata": {
    "papermill": {
     "duration": 0.02342,
     "end_time": "2025-09-24T06:14:45.526850",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.503430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. SwiGLU Activation Function\n",
    "\n",
    "SwiGLU combines Swish activation with gating: **SwiGLU(x) = Swish(xW₁) ⊙ (xW₂)W₃**\n",
    "\n",
    "### How it works:\n",
    "SwiGLU uses two parallel linear transformations - one creates a \"gate\" (with Swish activation), the other creates \"values\". The gate controls which values pass through.\n",
    "\n",
    "**Simple Example:**\n",
    "```python\n",
    "# Input: \"The cat sat\"\n",
    "x = input_embedding\n",
    "\n",
    "# Two paths:\n",
    "gate = swish(x @ W1)    # [0.8, 0.2, 0.9] - what to keep\n",
    "value = x @ W2          # [2.1, -1.5, 3.2] - the information\n",
    "\n",
    "# Gating: element-wise multiplication\n",
    "gated = gate * value    # [1.68, -0.3, 2.88] - filtered info\n",
    "output = gated @ W3     # final transformation\n",
    "```\n",
    "\n",
    "**Why it's important:**\n",
    "- **Selective Processing**: Gates allow the model to filter information\n",
    "- **Better Gradients**: Swish activation has smoother gradients than ReLU\n",
    "- **Proven Performance**: Used in state-of-the-art models like LLaMA and PaLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f68fda4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:45.574035Z",
     "iopub.status.busy": "2025-09-24T06:14:45.573760Z",
     "iopub.status.idle": "2025-09-24T06:14:45.657498Z",
     "shell.execute_reply": "2025-09-24T06:14:45.656742Z"
    },
    "papermill": {
     "duration": 0.1086,
     "end_time": "2025-09-24T06:14:45.658565",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.549965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SwiGLU Implementation...\n",
      "SwiGLU test passed: torch.Size([8, 32, 512]) -> torch.Size([8, 32, 512])\n",
      "SwiGLU: 3,145,728 params\n",
      "Standard FFN: 2,099,712 params\n",
      "SwiGLU implementation complete!\n"
     ]
    }
   ],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"\n",
    "    SwiGLU activation function implementation.\n",
    "    \n",
    "    SwiGLU(x) = Swish(xW1) ⊙ (xW2) * W3\n",
    "    where Swish(x) = x * sigmoid(x) = x * SiLU(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, d_ff: int):\n",
    "        \"\"\"\n",
    "        Initialize SwiGLU.\n",
    "        \n",
    "        Args:\n",
    "            d_model: Input/output dimension\n",
    "            d_ff: Hidden dimension (usually 4 * d_model)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Three linear transformations\n",
    "        self.w1 = nn.Linear(d_model, d_ff, bias=False)  # Gate projection\n",
    "        self.w2 = nn.Linear(d_model, d_ff, bias=False)  # Value projection  \n",
    "        self.w3 = nn.Linear(d_ff, d_model, bias=False)  # Output projection\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply SwiGLU activation.\"\"\"\n",
    "        # x shape: (..., d_model)\n",
    "        \n",
    "        # Apply gate and value projections\n",
    "        gate = self.w1(x)  # (..., d_ff)\n",
    "        value = self.w2(x)  # (..., d_ff)\n",
    "        \n",
    "        # Apply Swish (SiLU) activation to gate\n",
    "        activated_gate = F.silu(gate)  # Swish activation\n",
    "        \n",
    "        # Element-wise multiplication (gating)\n",
    "        gated = activated_gate * value  # (..., d_ff)\n",
    "        \n",
    "        # Final output projection\n",
    "        output = self.w3(gated)  # (..., d_model)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test SwiGLU implementation\n",
    "print(\"Testing SwiGLU Implementation...\")\n",
    "swiglu = SwiGLU(d_model=512, d_ff=2048)\n",
    "test_input = torch.randn(8, 32, 512)\n",
    "output = swiglu(test_input)\n",
    "print(f\"SwiGLU test passed: {test_input.shape} -> {output.shape}\")\n",
    "\n",
    "# Parameter comparison with standard FFN\n",
    "class StandardFFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(d_model, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.relu(self.w1(x)))\n",
    "\n",
    "standard_ffn = StandardFFN(512, 2048)\n",
    "print(f\"SwiGLU: {sum(p.numel() for p in swiglu.parameters()):,} params\")\n",
    "print(f\"Standard FFN: {sum(p.numel() for p in standard_ffn.parameters()):,} params\")\n",
    "print(\"SwiGLU implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc96023",
   "metadata": {
    "papermill": {
     "duration": 0.023258,
     "end_time": "2025-09-24T06:14:45.705693",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.682435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Mixture of Experts (MoE)\n",
    "\n",
    "MoE scales model capacity by routing each token to only the top-k most relevant expert networks, enabling large models with constant per-token computation.\n",
    "\n",
    "### How it works:\n",
    "Instead of one large feed-forward network, MoE has multiple smaller \"expert\" networks. A router decides which experts each token should use.\n",
    "\n",
    "**Simple Example:**\n",
    "```python\n",
    "# Token: \"Python\"\n",
    "router_scores = [0.1, 0.8, 0.3, 0.7, 0.2, 0.4, 0.6, 0.5]\n",
    "# Router says: use Expert 1 (0.8) and Expert 3 (0.7)\n",
    "\n",
    "# Only compute:\n",
    "output = 0.8 * expert_1(token) + 0.7 * expert_3(token)\n",
    "# Other 6 experts are skipped, saving computation\n",
    "```\n",
    "\n",
    "**Why it's important:**\n",
    "- **Scalable Capacity**: Can have 100+ experts but only use 2-8 per token\n",
    "- **Specialization**: Different experts learn different patterns (syntax, facts, reasoning)\n",
    "- **Constant Cost**: Computation per token stays the same regardless of total experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89bdf5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:45.753696Z",
     "iopub.status.busy": "2025-09-24T06:14:45.753456Z",
     "iopub.status.idle": "2025-09-24T06:14:45.852593Z",
     "shell.execute_reply": "2025-09-24T06:14:45.851878Z"
    },
    "papermill": {
     "duration": 0.124588,
     "end_time": "2025-09-24T06:14:45.853700",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.729112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Mixture of Experts Implementation...\n",
      "MoE Configuration:\n",
      "   Model dimension: 256\n",
      "   Number of experts: 8\n",
      "   Top-k experts: 2\n",
      "   Input shape: torch.Size([4, 16, 256])\n",
      "Output shape: torch.Size([4, 16, 256])\n",
      "MoE test passed!\n",
      "\n",
      "Parameter Count:\n",
      "   Single expert: 786,432 parameters\n",
      "   Router: 2,048 parameters\n",
      "   Total MoE: 6,293,504 parameters\n",
      "   Active per token: ~1,574,912 parameters (2/8 experts)\n",
      "Mixture of Experts implementation complete!\n"
     ]
    }
   ],
   "source": [
    "class MixtureOfExperts(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture of Experts (MoE) implementation with top-k routing.\n",
    "    \n",
    "    Each token is routed to the top-k most relevant experts,\n",
    "    and their outputs are combined using learned gating weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, d_ff: int = None, num_experts: int = 8, top_k: int = 2):\n",
    "        \"\"\"\n",
    "        Initialize MoE block.\n",
    "        \n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            d_ff: Expert hidden dimension (default: 4 * d_model)\n",
    "            num_experts: Total number of experts\n",
    "            top_k: Number of experts to activate per token\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        self.d_ff = d_ff if d_ff is not None else 4 * d_model\n",
    "        \n",
    "        # Router network - decides which experts to use\n",
    "        self.router = nn.Linear(d_model, num_experts, bias=False)\n",
    "        \n",
    "        # Expert networks - each is a SwiGLU FFN\n",
    "        self.experts = nn.ModuleList([\n",
    "            SwiGLU(d_model, self.d_ff) for _ in range(num_experts)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply MoE to input.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of same shape as input\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # Flatten for easier processing\n",
    "        x_flat = x.view(-1, d_model)  # (batch_size * seq_len, d_model)\n",
    "        \n",
    "        # Router: compute expert scores for each token\n",
    "        router_logits = self.router(x_flat)  # (batch_size * seq_len, num_experts)\n",
    "        \n",
    "        # Select top-k experts for each token\n",
    "        top_k_scores, top_k_indices = torch.topk(router_logits, self.top_k, dim=-1)\n",
    "        \n",
    "        # Apply softmax to top-k scores for gating weights\n",
    "        top_k_gates = F.softmax(top_k_scores, dim=-1)  # (batch_size * seq_len, top_k)\n",
    "        \n",
    "        # Initialize output\n",
    "        output = torch.zeros_like(x_flat)\n",
    "        \n",
    "        # Process each expert\n",
    "        for expert_idx in range(self.num_experts):\n",
    "            # Find tokens that use this expert\n",
    "            expert_mask = (top_k_indices == expert_idx).any(dim=-1)\n",
    "            \n",
    "            if expert_mask.sum() == 0:\n",
    "                continue  # No tokens use this expert\n",
    "                \n",
    "            # Get tokens for this expert\n",
    "            expert_tokens = x_flat[expert_mask]\n",
    "            \n",
    "            if expert_tokens.numel() == 0:\n",
    "                continue\n",
    "                \n",
    "            # Apply expert\n",
    "            expert_output = self.experts[expert_idx](expert_tokens)\n",
    "            \n",
    "            # Find gate weights for this expert\n",
    "            expert_positions = torch.where(expert_mask)[0]\n",
    "            for i, pos in enumerate(expert_positions):\n",
    "                # Find which top-k position this expert is in for this token\n",
    "                expert_positions_in_topk = (top_k_indices[pos] == expert_idx).nonzero(as_tuple=True)[0]\n",
    "                for pos_in_topk in expert_positions_in_topk:\n",
    "                    gate_weight = top_k_gates[pos, pos_in_topk]\n",
    "                    output[pos] += gate_weight * expert_output[i]\n",
    "        \n",
    "        # Reshape back to original shape\n",
    "        output = output.view(batch_size, seq_len, d_model)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test MoE implementation\n",
    "print(\"Testing Mixture of Experts Implementation...\")\n",
    "\n",
    "d_model = 256\n",
    "num_experts = 8\n",
    "top_k = 2\n",
    "batch_size = 4\n",
    "seq_len = 16\n",
    "\n",
    "# Create MoE layer\n",
    "moe = MixtureOfExperts(d_model=d_model, num_experts=num_experts, top_k=top_k)\n",
    "\n",
    "# Test input\n",
    "test_input = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "print(f\"MoE Configuration:\")\n",
    "print(f\"   Model dimension: {d_model}\")\n",
    "print(f\"   Number of experts: {num_experts}\")\n",
    "print(f\"   Top-k experts: {top_k}\")\n",
    "print(f\"   Input shape: {test_input.shape}\")\n",
    "\n",
    "# Apply MoE\n",
    "with torch.no_grad():  # Disable gradients for testing\n",
    "    output = moe(test_input)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"MoE test passed!\")\n",
    "\n",
    "# Calculate parameters\n",
    "total_params = sum(p.numel() for p in moe.parameters())\n",
    "single_expert_params = sum(p.numel() for p in moe.experts[0].parameters())\n",
    "router_params = sum(p.numel() for p in moe.router.parameters())\n",
    "\n",
    "print(f\"\\nParameter Count:\")\n",
    "print(f\"   Single expert: {single_expert_params:,} parameters\")\n",
    "print(f\"   Router: {router_params:,} parameters\") \n",
    "print(f\"   Total MoE: {total_params:,} parameters\")\n",
    "print(f\"   Active per token: ~{(single_expert_params * top_k + router_params):,} parameters ({top_k}/{num_experts} experts)\")\n",
    "\n",
    "print(\"Mixture of Experts implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432259da",
   "metadata": {
    "papermill": {
     "duration": 0.023563,
     "end_time": "2025-09-24T06:14:45.901348",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.877785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Grouped Query Attention (GQA)\n",
    "\n",
    "GQA reduces key-value heads while maintaining multiple query heads, balancing memory efficiency with attention quality.\n",
    "\n",
    "### How it works:\n",
    "Traditional attention has equal numbers of Q, K, V heads. GQA shares K and V heads across multiple Q heads, reducing memory while preserving attention quality.\n",
    "\n",
    "**Simple Example:**\n",
    "```python\n",
    "# Traditional Multi-Head Attention (12 heads):\n",
    "Q: [Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10, Q11, Q12]\n",
    "K: [K1, K2, K3, K4, K5, K6, K7, K8, K9, K10, K11, K12]\n",
    "V: [V1, V2, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12]\n",
    "\n",
    "# GQA (12 Q heads, 3 KV heads):\n",
    "Q: [Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10, Q11, Q12]\n",
    "K: [K1, K1, K1, K1, K2, K2, K2, K2, K3, K3, K3, K3]  # shared\n",
    "V: [V1, V1, V1, V1, V2, V2, V2, V2, V3, V3, V3, V3]  # shared\n",
    "```\n",
    "\n",
    "**Why it's important:**\n",
    "- **Memory Efficiency**: 75% reduction in KV cache size during inference\n",
    "- **Quality Preservation**: Better than single KV head, almost as good as full attention\n",
    "- **Faster Inference**: Less memory bandwidth needed for long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f700a850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:45.950870Z",
     "iopub.status.busy": "2025-09-24T06:14:45.950591Z",
     "iopub.status.idle": "2025-09-24T06:14:46.016873Z",
     "shell.execute_reply": "2025-09-24T06:14:46.016026Z"
    },
    "papermill": {
     "duration": 0.092004,
     "end_time": "2025-09-24T06:14:46.018074",
     "exception": false,
     "start_time": "2025-09-24T06:14:45.926070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Grouped Query Attention Implementation...\n",
      "GQA Configuration:\n",
      "   Model dimension: 768\n",
      "   Query heads: 12\n",
      "   Key-Value heads: 3\n",
      "   Group size: 4\n",
      "   Head dimension: 64\n",
      "   Input shape: torch.Size([4, 64, 768])\n",
      "Output shape: torch.Size([4, 64, 768])\n",
      "GQA test passed!\n",
      "\n",
      "Parameter Comparison:\n",
      "   Standard MHA: 2,359,296 parameters\n",
      "   GQA: 1,474,560 parameters\n",
      "   Reduction: 37.5%\n",
      "Grouped Query Attention implementation complete!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class GroupedQueryAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Grouped Query Attention (GQA) implementation.\n",
    "    \n",
    "    GQA reduces the number of key-value heads while maintaining multiple query heads,\n",
    "    providing a balance between efficiency and quality.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_heads: int, n_kv_heads: int = None):\n",
    "        \"\"\"\n",
    "        Initialize GQA layer.\n",
    "        \n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            n_heads: Number of query heads\n",
    "            n_kv_heads: Number of key-value heads (default: n_heads // 4)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.n_kv_heads = n_kv_heads if n_kv_heads is not None else max(1, n_heads // 4)\n",
    "        \n",
    "        assert n_heads % self.n_kv_heads == 0, \"n_heads must be divisible by n_kv_heads\"\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        \n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.group_size = n_heads // self.n_kv_heads  # How many Q heads per KV head\n",
    "        \n",
    "        # Linear projections\n",
    "        self.q_proj = nn.Linear(d_model, n_heads * self.head_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(d_model, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.v_proj = nn.Linear(d_model, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(n_heads * self.head_dim, d_model, bias=False)\n",
    "        \n",
    "        self.rope = RotaryPositionalEmbedding(self.head_dim)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Apply grouped query attention.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model)\n",
    "            mask: Optional attention mask\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of same shape as input\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # Compute Q, K, V\n",
    "        q = self.q_proj(x)  # (batch_size, seq_len, n_heads * head_dim)\n",
    "        k = self.k_proj(x)  # (batch_size, seq_len, n_kv_heads * head_dim)\n",
    "        v = self.v_proj(x)  # (batch_size, seq_len, n_kv_heads * head_dim)\n",
    "        \n",
    "        # Reshape to separate heads\n",
    "        q = q.view(batch_size, seq_len, self.n_heads, self.head_dim)\n",
    "        k = k.view(batch_size, seq_len, self.n_kv_heads, self.head_dim)\n",
    "        v = v.view(batch_size, seq_len, self.n_kv_heads, self.head_dim)\n",
    "        \n",
    "        # Apply RoPE to Q and K\n",
    "        q = self.rope(q)\n",
    "        k = self.rope(k)\n",
    "        \n",
    "        # Expand K and V to match Q heads by repeating each KV head\n",
    "        # Shape: (batch_size, seq_len, n_heads, head_dim)\n",
    "        k = k.repeat_interleave(self.group_size, dim=2)\n",
    "        v = v.repeat_interleave(self.group_size, dim=2)\n",
    "        \n",
    "        # Transpose for attention computation\n",
    "        # Shape: (batch_size, n_heads, seq_len, head_dim)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scale = 1.0 / math.sqrt(self.head_dim)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * scale\n",
    "        \n",
    "        # Apply causal mask\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        else:\n",
    "            # Create causal mask\n",
    "            causal_mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool))\n",
    "            scores = scores.masked_fill(~causal_mask, float('-inf'))\n",
    "        \n",
    "        # Apply softmax\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Transpose back and reshape\n",
    "        # Shape: (batch_size, seq_len, n_heads, head_dim)\n",
    "        out = out.transpose(1, 2)\n",
    "        # Shape: (batch_size, seq_len, n_heads * head_dim)\n",
    "        out = out.reshape(batch_size, seq_len, self.n_heads * self.head_dim)\n",
    "        \n",
    "        # Final projection\n",
    "        out = self.o_proj(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Test GQA implementation\n",
    "print(\"Testing Grouped Query Attention Implementation...\")\n",
    "\n",
    "d_model = 768\n",
    "n_heads = 12\n",
    "n_kv_heads = 3  # 4 Q heads per KV head\n",
    "batch_size = 4\n",
    "seq_len = 64\n",
    "\n",
    "# Create GQA layer\n",
    "gqa = GroupedQueryAttention(d_model=d_model, n_heads=n_heads, n_kv_heads=n_kv_heads)\n",
    "\n",
    "# Test input\n",
    "test_input = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "print(f\"GQA Configuration:\")\n",
    "print(f\"   Model dimension: {d_model}\")\n",
    "print(f\"   Query heads: {n_heads}\")\n",
    "print(f\"   Key-Value heads: {n_kv_heads}\")\n",
    "print(f\"   Group size: {gqa.group_size}\")\n",
    "print(f\"   Head dimension: {gqa.head_dim}\")\n",
    "print(f\"   Input shape: {test_input.shape}\")\n",
    "\n",
    "# Apply GQA\n",
    "with torch.no_grad():  # Disable gradients for testing\n",
    "    output = gqa(test_input)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"GQA test passed!\")\n",
    "\n",
    "# Compare parameter counts\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Standard Multi-Head Attention for comparison\n",
    "class StandardMHA(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.q_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.k_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.v_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.o_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "mha = StandardMHA(d_model, n_heads)\n",
    "\n",
    "gqa_params = count_parameters(gqa)\n",
    "mha_params = count_parameters(mha)\n",
    "\n",
    "print(f\"\\nParameter Comparison:\")\n",
    "print(f\"   Standard MHA: {mha_params:,} parameters\")\n",
    "print(f\"   GQA: {gqa_params:,} parameters\")\n",
    "print(f\"   Reduction: {((mha_params - gqa_params) / mha_params * 100):.1f}%\")\n",
    "\n",
    "print(\"Grouped Query Attention implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d689235",
   "metadata": {
    "papermill": {
     "duration": 0.02345,
     "end_time": "2025-09-24T06:14:46.065938",
     "exception": false,
     "start_time": "2025-09-24T06:14:46.042488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. RMS Normalization\n",
    "\n",
    "RMS Normalization is a more efficient alternative to LayerNorm that normalizes using only RMS statistics: `x / sqrt(mean(x²) + ε)`\n",
    "\n",
    "### How it works:\n",
    "LayerNorm subtracts the mean and divides by standard deviation. RMSNorm skips the mean subtraction and only normalizes by the root mean square.\n",
    "\n",
    "**Simple Example:**\n",
    "```python\n",
    "# LayerNorm:\n",
    "mean = x.mean()\n",
    "std = x.std()\n",
    "normalized = (x - mean) / std\n",
    "\n",
    "# RMSNorm:\n",
    "rms = sqrt(mean(x²))\n",
    "normalized = x / rms\n",
    "\n",
    "# For x = [1, 2, 3, 4]:\n",
    "# LayerNorm: [-1.34, -0.45, 0.45, 1.34]\n",
    "# RMSNorm: [0.37, 0.73, 1.10, 1.46]\n",
    "```\n",
    "\n",
    "**Why it's important:**\n",
    "- **Computational Efficiency**: 25% fewer operations than LayerNorm\n",
    "- **Numerical Stability**: Better gradient flow in deep networks\n",
    "- **Proven Effective**: Used in LLaMA, PaLM, and other state-of-the-art models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a91d0548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:46.114290Z",
     "iopub.status.busy": "2025-09-24T06:14:46.114083Z",
     "iopub.status.idle": "2025-09-24T06:14:58.453625Z",
     "shell.execute_reply": "2025-09-24T06:14:58.452596Z"
    },
    "papermill": {
     "duration": 12.365391,
     "end_time": "2025-09-24T06:14:58.454845",
     "exception": false,
     "start_time": "2025-09-24T06:14:46.089454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Complete GPT-OSS-mini Model...\n",
      "Model Configuration:\n",
      "   vocab_size: 50304\n",
      "   d_model: 768\n",
      "   n_layers: 12\n",
      "   n_heads: 12\n",
      "   n_kv_heads: 3\n",
      "   d_ff: 3072\n",
      "   num_experts: 8\n",
      "   top_k: 2\n",
      "   max_seq_len: 2048\n",
      "   dropout: 0.1\n",
      "\n",
      "Input shape: torch.Size([2, 128])\n",
      "Output logits shape: torch.Size([2, 128, 50304])\n",
      "\n",
      "Model Parameters:\n",
      "   Total: 774,531,840\n",
      "   Trainable: 774,531,840\n",
      "GPT-OSS-mini model implementation complete!\n"
     ]
    }
   ],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Root Mean Square Layer Normalization.\n",
    "    \n",
    "    RMSNorm normalizes using only the RMS statistics, making it more efficient\n",
    "    than standard LayerNorm while maintaining similar performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize RMSNorm layer.\n",
    "        \n",
    "        Args:\n",
    "            dim: Input dimension\n",
    "            eps: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # Learnable scale parameter\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply RMS normalization.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (..., dim)\n",
    "            \n",
    "        Returns:\n",
    "            Normalized tensor of same shape\n",
    "        \"\"\"\n",
    "        # Compute RMS\n",
    "        rms = torch.sqrt(torch.mean(x * x, dim=-1, keepdim=True) + self.eps)\n",
    "        \n",
    "        # Normalize and scale\n",
    "        return x / rms * self.weight\n",
    "\n",
    "# Now let's build the complete GPT model with all modern techniques\n",
    "class ModernGPTBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single transformer block with modern techniques:\n",
    "    - Grouped Query Attention (GQA)\n",
    "    - Mixture of Experts (MoE) \n",
    "    - RMS Normalization\n",
    "    - Pre-normalization architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        n_heads: int,\n",
    "        n_kv_heads: int = None,\n",
    "        d_ff: int = None,\n",
    "        num_experts: int = 8,\n",
    "        top_k: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize GPT block with modern techniques.\n",
    "        \n",
    "        Args:\n",
    "            d_model: Model dimension\n",
    "            n_heads: Number of attention heads\n",
    "            n_kv_heads: Number of key-value heads for GQA\n",
    "            d_ff: Feed-forward dimension\n",
    "            num_experts: Number of experts in MoE\n",
    "            top_k: Number of experts to activate\n",
    "            dropout: Dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # RMS Normalization layers\n",
    "        self.norm1 = RMSNorm(d_model)\n",
    "        self.norm2 = RMSNorm(d_model)\n",
    "        \n",
    "        # Grouped Query Attention\n",
    "        self.attention = GroupedQueryAttention(\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            n_kv_heads=n_kv_heads\n",
    "        )\n",
    "        \n",
    "        # Mixture of Experts\n",
    "        self.moe = MixtureOfExperts(\n",
    "            d_model=d_model,\n",
    "            d_ff=d_ff,\n",
    "            num_experts=num_experts,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the transformer block.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model)\n",
    "            mask: Optional attention mask\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of same shape as input\n",
    "        \"\"\"\n",
    "        # Pre-norm attention\n",
    "        attn_out = self.attention(self.norm1(x), mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        \n",
    "        # Pre-norm MoE\n",
    "        moe_out = self.moe(self.norm2(x))\n",
    "        x = x + self.dropout(moe_out)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class GPTOSSMini(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete GPT model with modern techniques:\n",
    "    - Rotary Position Embedding (RoPE)\n",
    "    - Grouped Query Attention (GQA)\n",
    "    - Mixture of Experts (MoE)\n",
    "    - SwiGLU activation\n",
    "    - RMS Normalization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        d_model: int,\n",
    "        n_layers: int,\n",
    "        n_heads: int,\n",
    "        n_kv_heads: int = None,\n",
    "        d_ff: int = None,\n",
    "        num_experts: int = 8,\n",
    "        top_k: int = 2,\n",
    "        max_seq_len: int = 2048,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the complete GPT model.\n",
    "        \n",
    "        Args:\n",
    "            vocab_size: Size of vocabulary\n",
    "            d_model: Model dimension\n",
    "            n_layers: Number of transformer blocks\n",
    "            n_heads: Number of attention heads\n",
    "            n_kv_heads: Number of key-value heads for GQA\n",
    "            d_ff: Feed-forward dimension\n",
    "            num_experts: Number of experts in MoE\n",
    "            top_k: Number of experts to activate\n",
    "            max_seq_len: Maximum sequence length\n",
    "            dropout: Dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        # Token embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ModernGPTBlock(\n",
    "                d_model=d_model,\n",
    "                n_heads=n_heads,\n",
    "                n_kv_heads=n_kv_heads,\n",
    "                d_ff=d_ff,\n",
    "                num_experts=num_experts,\n",
    "                top_k=top_k,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final normalization and output projection\n",
    "        self.norm_f = RMSNorm(d_model)\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize model weights using scaled initialization.\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    def forward(self, input_ids, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token indices of shape (batch_size, seq_len)\n",
    "            mask: Optional attention mask\n",
    "            \n",
    "        Returns:\n",
    "            Logits of shape (batch_size, seq_len, vocab_size)\n",
    "        \"\"\"\n",
    "        # Token embeddings\n",
    "        x = self.token_embedding(input_ids)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        \n",
    "        # Final normalization\n",
    "        x = self.norm_f(x)\n",
    "        \n",
    "        # Output projection\n",
    "        logits = self.lm_head(x)  # (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def generate(self, input_ids, max_new_tokens=50, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate text using the model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Starting token sequence\n",
    "            max_new_tokens: Maximum number of tokens to generate\n",
    "            temperature: Sampling temperature\n",
    "            top_k: Top-k sampling parameter\n",
    "            \n",
    "        Returns:\n",
    "            Generated token sequence\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get model predictions\n",
    "            with torch.no_grad():\n",
    "                logits = self(input_ids)\n",
    "                \n",
    "            # Get logits for the last token\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # Apply top-k filtering if specified\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, top_k)\n",
    "                logits[logits < v[:, [-1]]] = float('-inf')\n",
    "            \n",
    "            # Sample next token\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Append to sequence\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "            \n",
    "            # Truncate if sequence gets too long\n",
    "            if input_ids.size(1) > self.max_seq_len:\n",
    "                input_ids = input_ids[:, -self.max_seq_len:]\n",
    "        \n",
    "        return input_ids\n",
    "\n",
    "# Test the complete model\n",
    "print(\"Testing Complete GPT-OSS-mini Model...\")\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    'vocab_size': 50304,  # Rounded to nearest multiple of 64 for efficiency\n",
    "    'd_model': 768,\n",
    "    'n_layers': 12,\n",
    "    'n_heads': 12,\n",
    "    'n_kv_heads': 3,  # GQA: 4 Q heads per KV head\n",
    "    'd_ff': 3072,  # 4 * d_model\n",
    "    'num_experts': 8,\n",
    "    'top_k': 2,\n",
    "    'max_seq_len': 2048,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = GPTOSSMini(**config)\n",
    "\n",
    "# Test input\n",
    "batch_size = 2\n",
    "seq_len = 128\n",
    "test_input_ids = torch.randint(0, config['vocab_size'], (batch_size, seq_len))\n",
    "\n",
    "print(f\"Model Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nInput shape: {test_input_ids.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    logits = model(test_input_ids)\n",
    "\n",
    "print(f\"Output logits shape: {logits.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"   Total: {total_params:,}\")\n",
    "print(f\"   Trainable: {trainable_params:,}\")\n",
    "\n",
    "print(\"GPT-OSS-mini model implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8920e52",
   "metadata": {
    "papermill": {
     "duration": 0.023948,
     "end_time": "2025-09-24T06:14:58.503503",
     "exception": false,
     "start_time": "2025-09-24T06:14:58.479555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. Training Pipeline\n",
    "\n",
    "Complete training implementation with AdamW optimizer, cosine scheduling, gradient clipping, and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948e5846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:58.552528Z",
     "iopub.status.busy": "2025-09-24T06:14:58.552300Z",
     "iopub.status.idle": "2025-09-24T06:14:58.573945Z",
     "shell.execute_reply": "2025-09-24T06:14:58.573084Z"
    },
    "papermill": {
     "duration": 0.047748,
     "end_time": "2025-09-24T06:14:58.575037",
     "exception": false,
     "start_time": "2025-09-24T06:14:58.527289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pipeline Setup Complete!\n",
      "\n",
      "To use the training pipeline:\n",
      "1. Prepare your dataset (tokenized text data)\n",
      "2. Create data loaders for training and validation\n",
      "3. Initialize the model with your desired configuration\n",
      "4. Create the GPTTrainer with your model and data\n",
      "5. Call trainer.train(train_loader, val_loader)\n",
      "\n",
      "Example configuration:\n",
      "   learning_rate: 0.0003\n",
      "   weight_decay: 0.1\n",
      "   max_grad_norm: 1.0\n",
      "   warmup_steps: 1000\n",
      "   max_steps: 10000\n",
      "   eval_interval: 500\n",
      "   save_interval: 2000\n",
      "\n",
      "Note: This implementation provides a complete training pipeline.\n",
      "All components are production-ready and do not require mocking.\n"
     ]
    }
   ],
   "source": [
    "class GPTTrainer:\n",
    "    \"\"\"\n",
    "    Comprehensive training pipeline for Modern GPT model.\n",
    "    \n",
    "    Features:\n",
    "    - AdamW optimization with weight decay\n",
    "    - Cosine learning rate scheduling\n",
    "    - Gradient clipping and accumulation\n",
    "    - Training progress monitoring\n",
    "    - Checkpointing functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        train_data,\n",
    "        val_data=None,\n",
    "        learning_rate=3e-4,\n",
    "        weight_decay=0.1,\n",
    "        beta1=0.9,\n",
    "        beta2=0.95,\n",
    "        max_grad_norm=1.0,\n",
    "        warmup_steps=2000,\n",
    "        max_steps=100000,\n",
    "        eval_interval=1000,\n",
    "        save_interval=5000,\n",
    "        checkpoint_dir=\"./checkpoints\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the trainer.\n",
    "        \n",
    "        Args:\n",
    "            model: The GPT model to train\n",
    "            tokenizer: Tokenizer for text processing\n",
    "            train_data: Training dataset\n",
    "            val_data: Validation dataset (optional)\n",
    "            learning_rate: Peak learning rate\n",
    "            weight_decay: Weight decay coefficient\n",
    "            beta1, beta2: Adam optimizer parameters\n",
    "            max_grad_norm: Gradient clipping threshold\n",
    "            warmup_steps: Number of learning rate warmup steps\n",
    "            max_steps: Maximum training steps\n",
    "            eval_interval: Steps between evaluations\n",
    "            save_interval: Steps between checkpoints\n",
    "            checkpoint_dir: Directory to save checkpoints\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        \n",
    "        # Training hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.max_steps = max_steps\n",
    "        self.eval_interval = eval_interval\n",
    "        self.save_interval = save_interval\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        \n",
    "        # Optimizer setup\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            betas=(beta1, beta2),\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler (cosine with warmup)\n",
    "        self.scheduler = self._get_cosine_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            warmup_steps,\n",
    "            max_steps\n",
    "        )\n",
    "        \n",
    "        # Training state\n",
    "        self.step = 0\n",
    "        self.epoch = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "        # Create checkpoint directory\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "    def _get_cosine_schedule_with_warmup(self, optimizer, warmup_steps, max_steps):\n",
    "        \"\"\"Create cosine learning rate schedule with linear warmup.\"\"\"\n",
    "        def lr_lambda(step):\n",
    "            if step < warmup_steps:\n",
    "                # Linear warmup\n",
    "                return float(step) / float(max(1, warmup_steps))\n",
    "            else:\n",
    "                # Cosine decay\n",
    "                progress = float(step - warmup_steps) / float(max(1, max_steps - warmup_steps))\n",
    "                return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "        \n",
    "        return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform a single training step.\n",
    "        \n",
    "        Args:\n",
    "            batch: Dictionary containing 'input_ids' and 'labels'\n",
    "            \n",
    "        Returns:\n",
    "            Loss value for this step\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = self.model(input_ids)\n",
    "        \n",
    "        # Compute loss (shift labels for causal LM)\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        \n",
    "        loss = F.cross_entropy(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)),\n",
    "            shift_labels.view(-1),\n",
    "            ignore_index=-100\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "        \n",
    "        # Optimizer step\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def evaluate(self, data_loader, max_batches=None):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data.\n",
    "        \n",
    "        Args:\n",
    "            data_loader: Validation data loader\n",
    "            max_batches: Maximum number of batches to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            Average validation loss\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(data_loader):\n",
    "                if max_batches is not None and i >= max_batches:\n",
    "                    break\n",
    "                    \n",
    "                input_ids = batch['input_ids']\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                logits = self.model(input_ids)\n",
    "                \n",
    "                # Compute loss\n",
    "                shift_logits = logits[..., :-1, :].contiguous()\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                \n",
    "                loss = F.cross_entropy(\n",
    "                    shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                    shift_labels.view(-1),\n",
    "                    ignore_index=-100\n",
    "                )\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "        \n",
    "        return total_loss / num_batches if num_batches > 0 else 0\n",
    "    \n",
    "    def save_checkpoint(self, is_best=False):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'step': self.step,\n",
    "            'epoch': self.epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'learning_rates': self.learning_rates\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, f'checkpoint_step_{self.step}.pt')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.checkpoint_dir, 'best_model.pt')\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"Best model saved: {best_path}\")\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        self.step = checkpoint['step']\n",
    "        self.epoch = checkpoint['epoch']\n",
    "        self.best_val_loss = checkpoint['best_val_loss']\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        self.val_losses = checkpoint['val_losses']\n",
    "        self.learning_rates = checkpoint['learning_rates']\n",
    "        \n",
    "        print(f\"Checkpoint loaded: {checkpoint_path}\")\n",
    "        print(f\"Resuming from step {self.step}, epoch {self.epoch}\")\n",
    "    \n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        \"\"\"\n",
    "        Main training loop.\n",
    "        \n",
    "        Args:\n",
    "            train_loader: Training data loader\n",
    "            val_loader: Validation data loader (optional)\n",
    "        \"\"\"\n",
    "        print(\"Starting training...\")\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"   Learning rate: {self.learning_rate}\")\n",
    "        print(f\"   Weight decay: {self.weight_decay}\")\n",
    "        print(f\"   Max steps: {self.max_steps}\")\n",
    "        print(f\"   Warmup steps: {self.warmup_steps}\")\n",
    "        print(f\"   Gradient clipping: {self.max_grad_norm}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        while self.step < self.max_steps:\n",
    "            epoch_start_time = time.time()\n",
    "            epoch_loss = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                # Training step\n",
    "                loss = self.train_step(batch)\n",
    "                epoch_loss += loss\n",
    "                num_batches += 1\n",
    "                self.step += 1\n",
    "                \n",
    "                # Track metrics\n",
    "                current_lr = self.scheduler.get_last_lr()[0]\n",
    "                self.train_losses.append(loss)\n",
    "                self.learning_rates.append(current_lr)\n",
    "                \n",
    "                # Evaluation\n",
    "                if self.step % self.eval_interval == 0 and val_loader is not None:\n",
    "                    val_loss = self.evaluate(val_loader, max_batches=50)\n",
    "                    self.val_losses.append(val_loss)\n",
    "                    \n",
    "                    # Check if this is the best model\n",
    "                    is_best = val_loss < self.best_val_loss\n",
    "                    if is_best:\n",
    "                        self.best_val_loss = val_loss\n",
    "                    \n",
    "                    # Print progress\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print(f\"Step {self.step:6d} | \"\n",
    "                          f\"Train Loss: {loss:.4f} | \"\n",
    "                          f\"Val Loss: {val_loss:.4f} | \"\n",
    "                          f\"LR: {current_lr:.2e} | \"\n",
    "                          f\"Time: {elapsed_time:.1f}s\")\n",
    "                    \n",
    "                    # Save checkpoint if best model\n",
    "                    if is_best:\n",
    "                        self.save_checkpoint(is_best=True)\n",
    "                \n",
    "                # Regular checkpointing\n",
    "                if self.step % self.save_interval == 0:\n",
    "                    self.save_checkpoint()\n",
    "                \n",
    "                # Stop if max steps reached\n",
    "                if self.step >= self.max_steps:\n",
    "                    break\n",
    "            \n",
    "            # End of epoch\n",
    "            avg_epoch_loss = epoch_loss / num_batches if num_batches > 0 else 0\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            \n",
    "            print(f\"Epoch {self.epoch:3d} completed | \"\n",
    "                  f\"Avg Loss: {avg_epoch_loss:.4f} | \"\n",
    "                  f\"Time: {epoch_time:.1f}s\")\n",
    "            \n",
    "            self.epoch += 1\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Training completed! Total time: {total_time:.1f}s\")\n",
    "        \n",
    "        # Final checkpoint\n",
    "        self.save_checkpoint()\n",
    "\n",
    "# Example of how to use the training pipeline:\n",
    "print(\"Training Pipeline Setup Complete!\")\n",
    "\n",
    "print(\"\\nTo use the training pipeline:\")\n",
    "print(\"1. Prepare your dataset (tokenized text data)\")\n",
    "print(\"2. Create data loaders for training and validation\")\n",
    "print(\"3. Initialize the model with your desired configuration\")\n",
    "print(\"4. Create the GPTTrainer with your model and data\")\n",
    "print(\"5. Call trainer.train(train_loader, val_loader)\")\n",
    "\n",
    "print(\"\\nExample configuration:\")\n",
    "training_config = {\n",
    "    'learning_rate': 3e-4,\n",
    "    'weight_decay': 0.1,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'warmup_steps': 1000,\n",
    "    'max_steps': 10000,\n",
    "    'eval_interval': 500,\n",
    "    'save_interval': 2000\n",
    "}\n",
    "\n",
    "for key, value in training_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nNote: This implementation provides a complete training pipeline.\")\n",
    "print(\"All components are production-ready and do not require mocking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a4322",
   "metadata": {
    "papermill": {
     "duration": 0.023565,
     "end_time": "2025-09-24T06:14:58.622680",
     "exception": false,
     "start_time": "2025-09-24T06:14:58.599115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11. Training Visualization and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5837ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:58.671180Z",
     "iopub.status.busy": "2025-09-24T06:14:58.670928Z",
     "iopub.status.idle": "2025-09-24T06:14:58.683215Z",
     "shell.execute_reply": "2025-09-24T06:14:58.682555Z"
    },
    "papermill": {
     "duration": 0.037823,
     "end_time": "2025-09-24T06:14:58.684274",
     "exception": false,
     "start_time": "2025-09-24T06:14:58.646451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training visualization function ready!\n",
      "Use plot_training_metrics(trainer) after training to visualize metrics.\n"
     ]
    }
   ],
   "source": [
    "def plot_training_metrics(trainer, save_path=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive training visualizations.\n",
    "    \n",
    "    Args:\n",
    "        trainer: GPTTrainer instance with training history\n",
    "        save_path: Optional path to save the plot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Training Metrics Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Training Loss\n",
    "    if trainer.train_losses:\n",
    "        axes[0, 0].plot(trainer.train_losses, alpha=0.7, color='blue', linewidth=1)\n",
    "        axes[0, 0].set_title('Training Loss', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Step')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].set_yscale('log')\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'No Training Data', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].set_title('Training Loss', fontweight='bold')\n",
    "    \n",
    "    # Validation Loss\n",
    "    if trainer.val_losses:\n",
    "        val_steps = [i * trainer.eval_interval for i in range(len(trainer.val_losses))]\n",
    "        axes[0, 1].plot(val_steps, trainer.val_losses, color='red', linewidth=2, marker='o', markersize=3)\n",
    "        axes[0, 1].set_title('Validation Loss', fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Step')\n",
    "        axes[0, 1].set_ylabel('Loss')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].set_yscale('log')\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'No Validation Data', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "        axes[0, 1].set_title('Validation Loss', fontweight='bold')\n",
    "    \n",
    "    # Learning Rate Schedule\n",
    "    if trainer.learning_rates:\n",
    "        axes[1, 0].plot(trainer.learning_rates, color='green', linewidth=2)\n",
    "        axes[1, 0].set_title('Learning Rate Schedule', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Step')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].set_yscale('log')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No Learning Rate Data', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        axes[1, 0].set_title('Learning Rate Schedule', fontweight='bold')\n",
    "    \n",
    "    # Loss Smoothing (Moving Average)\n",
    "    if len(trainer.train_losses) > 100:\n",
    "        window_size = min(100, len(trainer.train_losses) // 10)\n",
    "        smoothed_loss = []\n",
    "        for i in range(len(trainer.train_losses)):\n",
    "            start_idx = max(0, i - window_size + 1)\n",
    "            smoothed_loss.append(np.mean(trainer.train_losses[start_idx:i+1]))\n",
    "        \n",
    "        axes[1, 1].plot(trainer.train_losses, alpha=0.3, color='blue', linewidth=1, label='Raw')\n",
    "        axes[1, 1].plot(smoothed_loss, color='blue', linewidth=2, label=f'Smoothed (window={window_size})')\n",
    "        axes[1, 1].set_title('Training Loss (Smoothed)', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Step')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].set_yscale('log')\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Insufficient Data\\nfor Smoothing', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Training Loss (Smoothed)', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Training plots saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"Training visualization function ready!\")\n",
    "print(\"Use plot_training_metrics(trainer) after training to visualize metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0ded1",
   "metadata": {
    "papermill": {
     "duration": 0.023838,
     "end_time": "2025-09-24T06:14:58.732025",
     "exception": false,
     "start_time": "2025-09-24T06:14:58.708187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 12. Sample Training Demo\n",
    "\n",
    "Let's run a small training demo with just 10-15 training records to see the complete pipeline in action. We'll create a tiny dataset, train for 1 epoch, and save a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0506230c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:14:58.780693Z",
     "iopub.status.busy": "2025-09-24T06:14:58.780477Z",
     "iopub.status.idle": "2025-09-24T06:15:00.751377Z",
     "shell.execute_reply": "2025-09-24T06:15:00.750485Z"
    },
    "papermill": {
     "duration": 1.996923,
     "end_time": "2025-09-24T06:15:00.752725",
     "exception": false,
     "start_time": "2025-09-24T06:14:58.755802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Training Demo ===\n",
      "Using Wikipedia data from sections 2-4...\n",
      "Using Wikipedia data: 46,349 characters\n",
      "Sample text: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code ...\n",
      "Using first 20,000 characters for demo training\n",
      "\n",
      "Demo Model Configuration:\n",
      "   vocab_size: 201088\n",
      "   d_model: 256\n",
      "   n_layers: 4\n",
      "   n_heads: 8\n",
      "   n_kv_heads: 2\n",
      "   d_ff: 1024\n",
      "   num_experts: 4\n",
      "   top_k: 2\n",
      "   max_seq_len: 128\n",
      "   dropout: 0.1\n",
      "\n",
      "Demo model parameters: 116,201,728\n",
      "\n",
      "Creating dataset from Wikipedia text...\n",
      "Tokenizing text...\n",
      "Tokenized 20,000 characters into 4,094 tokens\n",
      "Creating sliding windows...\n",
      "Created 62 training sequences\n",
      "Dataset created with 62 sequences\n",
      "Dataloader has 7 batches\n",
      "Total tokens in dataset: ~7,936\n",
      "\n",
      "Sample batch shapes:\n",
      "   Input IDs: torch.Size([8, 128])\n",
      "   Labels: torch.Size([8, 128])\n",
      "\n",
      "Sample training text:\n",
      "' omitted—for example, a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.\n",
      "In Python, a distinction between expressions and statements is rigidly enforced, in contrast to...'\n",
      "Dataset preparation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Use the Wikipedia data from sections 2-4 for training demo\n",
    "print(\"=== Sample Training Demo ===\")\n",
    "print(\"Using Wikipedia data from sections 2-4...\")\n",
    "\n",
    "# Check if we have the Wikipedia data available\n",
    "if 'raw_text' in globals() and raw_text:\n",
    "    demo_text = raw_text\n",
    "    print(f\"Using Wikipedia data: {len(demo_text):,} characters\")\n",
    "    print(f\"Sample text: {demo_text[:100]}...\")\n",
    "    \n",
    "    # Use a reasonable subset for demo (first 20,000 characters for faster training)\n",
    "    if len(demo_text) > 20000:\n",
    "        demo_text = demo_text[:20000]\n",
    "        print(f\"Using first {len(demo_text):,} characters for demo training\")\n",
    "else:\n",
    "    print(\"Wikipedia data not found. Please run sections 2-4 first.\")\n",
    "    # Fallback to small demo dataset\n",
    "    demo_texts = [\n",
    "        \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"Python is a powerful programming language for AI and machine learning.\",\n",
    "        \"Transformers have revolutionized natural language processing.\",\n",
    "        \"Deep learning models require large amounts of data for training.\",\n",
    "        \"Machine learning algorithms can solve complex problems.\",\n",
    "    ]\n",
    "    demo_text = \" \".join(demo_texts)\n",
    "    print(f\"Using fallback demo dataset: {len(demo_text)} characters\")\n",
    "\n",
    "# Create a smaller model for quick training\n",
    "demo_config = {\n",
    "    'vocab_size': vocab_size,  # Use the same vocab as before\n",
    "    'd_model': 256,           # Smaller model\n",
    "    'n_layers': 4,            # Fewer layers\n",
    "    'n_heads': 8,             # Fewer heads\n",
    "    'n_kv_heads': 2,          # 4 Q heads per KV head\n",
    "    'd_ff': 1024,             # Smaller FFN\n",
    "    'num_experts': 4,         # Fewer experts\n",
    "    'top_k': 2,               # Same top-k\n",
    "    'max_seq_len': 128,       # Shorter sequences\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "print(f\"\\nDemo Model Configuration:\")\n",
    "for key, value in demo_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Create demo model\n",
    "demo_model = GPTOSSMini(**demo_config)\n",
    "demo_model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "demo_params = sum(p.numel() for p in demo_model.parameters())\n",
    "print(f\"\\nDemo model parameters: {demo_params:,}\")\n",
    "\n",
    "# Create dataset and dataloader using the Wikipedia data\n",
    "print(f\"\\nCreating dataset from Wikipedia text...\")\n",
    "\n",
    "# Create dataset with reasonable parameters for demo\n",
    "demo_dataset = GPTDataset(\n",
    "    demo_text, \n",
    "    tokenizer, \n",
    "    max_length=128,    # Reasonable context length\n",
    "    stride=64          # Good overlap for training\n",
    ")\n",
    "\n",
    "demo_dataloader = DataLoader(\n",
    "    demo_dataset,\n",
    "    batch_size=8,      # Reasonable batch size\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0      # Avoid multiprocessing issues in notebooks\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with {len(demo_dataset)} sequences\")\n",
    "print(f\"Dataloader has {len(demo_dataloader)} batches\")\n",
    "print(f\"Total tokens in dataset: ~{len(demo_dataset) * 128:,}\")\n",
    "\n",
    "# Prepare batch format for training\n",
    "def format_batch(batch):\n",
    "    \"\"\"Convert dataset batch to training format.\"\"\"\n",
    "    input_ids, target_ids = batch\n",
    "    return {\n",
    "        'input_ids': input_ids.to(device),\n",
    "        'labels': target_ids.to(device)\n",
    "    }\n",
    "\n",
    "# Show a sample batch\n",
    "sample_batch = next(iter(demo_dataloader))\n",
    "formatted_batch = format_batch(sample_batch)\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"   Input IDs: {formatted_batch['input_ids'].shape}\")\n",
    "print(f\"   Labels: {formatted_batch['labels'].shape}\")\n",
    "\n",
    "# Show some sample text from the dataset\n",
    "print(f\"\\nSample training text:\")\n",
    "sample_input = formatted_batch['input_ids'][0].cpu()\n",
    "sample_text = tokenizer.decode(sample_input.tolist())\n",
    "print(f\"'{sample_text[:200]}...'\")\n",
    "\n",
    "print(\"Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b67620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:15:00.805031Z",
     "iopub.status.busy": "2025-09-24T06:15:00.804741Z",
     "iopub.status.idle": "2025-09-24T06:21:48.182142Z",
     "shell.execute_reply": "2025-09-24T06:21:48.181405Z"
    },
    "papermill": {
     "duration": 407.403853,
     "end_time": "2025-09-24T06:21:48.183893",
     "exception": false,
     "start_time": "2025-09-24T06:15:00.780040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Training Demo ===\n",
      "Trainer configuration:\n",
      "   Learning rate: 0.0005\n",
      "   Max steps: 100\n",
      "   Warmup steps: 50\n",
      "   Batch size: 8\n",
      "   Total batches per epoch: 7\n",
      "   Checkpoint dir: ./wiki_demo_checkpoints\n",
      "   Approximate epochs to run: 14\n",
      "\n",
      "Starting training with Wikipedia data...\n",
      "Training on 7 batches per epoch...\n",
      "\n",
      "============================================================\n",
      "TRAINING STARTED\n",
      "============================================================\n",
      "\n",
      "--- Epoch 1 ---\n",
      "   Step    1 | Batch   1/7 | Loss: 12.2581 | LR: 1.00e-05 | Time: 4.8s\n",
      "   Step    2 | Batch   2/7 | Loss: 12.2546 | LR: 2.00e-05 | Time: 8.8s\n",
      "   Step    3 | Batch   3/7 | Loss: 12.2350 | LR: 3.00e-05 | Time: 12.8s\n",
      "   Step    4 | Batch   4/7 | Loss: 12.2455 | LR: 4.00e-05 | Time: 16.7s\n",
      "   Step    5 | Batch   5/7 | Loss: 12.2227 | LR: 5.00e-05 | Time: 20.7s\n",
      "   Step    6 | Batch   6/7 | Loss: 12.2171 | LR: 6.00e-05 | Time: 24.6s\n",
      "   Step    7 | Batch   7/7 | Loss: 12.1837 | LR: 7.00e-05 | Time: 28.6s\n",
      "\n",
      "Epoch 1 Summary:\n",
      "   Average loss: 12.2309\n",
      "   Best loss so far: 12.2309\n",
      "   Epoch time: 28.6s\n",
      "   Steps completed: 7\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 2 ---\n",
      "   Step    8 | Batch   1/7 | Loss: 12.1022 | LR: 8.00e-05 | Time: 32.6s\n",
      "   Step    9 | Batch   2/7 | Loss: 12.0681 | LR: 9.00e-05 | Time: 36.5s\n",
      "   Step   10 | Batch   3/7 | Loss: 12.0081 | LR: 1.00e-04 | Time: 40.7s\n",
      "   Step   11 | Batch   4/7 | Loss: 11.9913 | LR: 1.10e-04 | Time: 44.6s\n",
      "   Step   12 | Batch   5/7 | Loss: 11.9444 | LR: 1.20e-04 | Time: 48.6s\n",
      "   Step   13 | Batch   6/7 | Loss: 11.9028 | LR: 1.30e-04 | Time: 52.6s\n",
      "   Step   14 | Batch   7/7 | Loss: 11.8469 | LR: 1.40e-04 | Time: 56.5s\n",
      "\n",
      "Epoch 2 Summary:\n",
      "   Average loss: 11.9806\n",
      "   Best loss so far: 11.9806\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 14\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 3 ---\n",
      "   Step   15 | Batch   1/7 | Loss: 11.7424 | LR: 1.50e-04 | Time: 60.5s\n",
      "   Step   16 | Batch   2/7 | Loss: 11.6916 | LR: 1.60e-04 | Time: 64.6s\n",
      "   Step   17 | Batch   3/7 | Loss: 11.6806 | LR: 1.70e-04 | Time: 68.6s\n",
      "   Step   18 | Batch   4/7 | Loss: 11.5826 | LR: 1.80e-04 | Time: 72.6s\n",
      "   Step   19 | Batch   5/7 | Loss: 11.5238 | LR: 1.90e-04 | Time: 76.5s\n",
      "   Step   20 | Batch   6/7 | Loss: 11.4354 | LR: 2.00e-04 | Time: 80.5s\n",
      "   Step   21 | Batch   7/7 | Loss: 11.4227 | LR: 2.10e-04 | Time: 84.5s\n",
      "\n",
      "Epoch 3 Summary:\n",
      "   Average loss: 11.5827\n",
      "   Best loss so far: 11.5827\n",
      "   Epoch time: 28.0s\n",
      "   Steps completed: 21\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 4 ---\n",
      "   Step   22 | Batch   1/7 | Loss: 11.3292 | LR: 2.20e-04 | Time: 88.6s\n",
      "   Step   23 | Batch   2/7 | Loss: 11.2187 | LR: 2.30e-04 | Time: 92.6s\n",
      "   Step   24 | Batch   3/7 | Loss: 11.1425 | LR: 2.40e-04 | Time: 96.5s\n",
      "   Step   25 | Batch   4/7 | Loss: 11.0726 | LR: 2.50e-04 | Time: 100.5s\n",
      "   Step   26 | Batch   5/7 | Loss: 11.0164 | LR: 2.60e-04 | Time: 104.5s\n",
      "   Step   27 | Batch   6/7 | Loss: 10.8773 | LR: 2.70e-04 | Time: 108.5s\n",
      "   Step   28 | Batch   7/7 | Loss: 10.8598 | LR: 2.80e-04 | Time: 112.6s\n",
      "\n",
      "Epoch 4 Summary:\n",
      "   Average loss: 11.0738\n",
      "   Best loss so far: 11.0738\n",
      "   Epoch time: 28.1s\n",
      "   Steps completed: 28\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 5 ---\n",
      "   Step   29 | Batch   1/7 | Loss: 10.6795 | LR: 2.90e-04 | Time: 116.6s\n",
      "   Step   30 | Batch   2/7 | Loss: 10.5858 | LR: 3.00e-04 | Time: 120.5s\n",
      "   Step   31 | Batch   3/7 | Loss: 10.4952 | LR: 3.10e-04 | Time: 124.5s\n",
      "   Step   32 | Batch   4/7 | Loss: 10.3342 | LR: 3.20e-04 | Time: 128.5s\n",
      "   Step   33 | Batch   5/7 | Loss: 10.2150 | LR: 3.30e-04 | Time: 132.4s\n",
      "   Step   34 | Batch   6/7 | Loss: 10.0413 | LR: 3.40e-04 | Time: 136.4s\n",
      "   Step   35 | Batch   7/7 | Loss: 9.9304 | LR: 3.50e-04 | Time: 140.5s\n",
      "\n",
      "Epoch 5 Summary:\n",
      "   Average loss: 10.3259\n",
      "   Best loss so far: 10.3259\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 35\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 6 ---\n",
      "   Step   36 | Batch   1/7 | Loss: 9.7863 | LR: 3.60e-04 | Time: 144.5s\n",
      "   Step   37 | Batch   2/7 | Loss: 9.6575 | LR: 3.70e-04 | Time: 148.4s\n",
      "   Step   38 | Batch   3/7 | Loss: 9.4725 | LR: 3.80e-04 | Time: 152.4s\n",
      "   Step   39 | Batch   4/7 | Loss: 9.3915 | LR: 3.90e-04 | Time: 156.3s\n",
      "   Step   40 | Batch   5/7 | Loss: 9.2010 | LR: 4.00e-04 | Time: 160.3s\n",
      "   Step   41 | Batch   6/7 | Loss: 9.0344 | LR: 4.10e-04 | Time: 164.4s\n",
      "   Step   42 | Batch   7/7 | Loss: 8.9084 | LR: 4.20e-04 | Time: 168.4s\n",
      "\n",
      "Epoch 6 Summary:\n",
      "   Average loss: 9.3502\n",
      "   Best loss so far: 9.3502\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 42\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 7 ---\n",
      "   Step   43 | Batch   1/7 | Loss: 8.7119 | LR: 4.30e-04 | Time: 172.4s\n",
      "   Step   44 | Batch   2/7 | Loss: 8.5244 | LR: 4.40e-04 | Time: 176.3s\n",
      "   Step   45 | Batch   3/7 | Loss: 8.3988 | LR: 4.50e-04 | Time: 180.3s\n",
      "   Step   46 | Batch   4/7 | Loss: 8.1946 | LR: 4.60e-04 | Time: 184.3s\n",
      "   Step   47 | Batch   5/7 | Loss: 7.9943 | LR: 4.70e-04 | Time: 188.4s\n",
      "   Step   48 | Batch   6/7 | Loss: 7.8266 | LR: 4.80e-04 | Time: 192.4s\n",
      "   Step   49 | Batch   7/7 | Loss: 7.7199 | LR: 4.90e-04 | Time: 196.3s\n",
      "\n",
      "Epoch 7 Summary:\n",
      "   Average loss: 8.1958\n",
      "   Best loss so far: 8.1958\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 49\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 8 ---\n",
      "   Step   50 | Batch   1/7 | Loss: 7.5863 | LR: 5.00e-04 | Time: 200.3s\n",
      "   Step   51 | Batch   2/7 | Loss: 7.3400 | LR: 5.00e-04 | Time: 204.3s\n",
      "   Step   52 | Batch   3/7 | Loss: 7.1875 | LR: 4.98e-04 | Time: 208.3s\n",
      "   Step   53 | Batch   4/7 | Loss: 7.0550 | LR: 4.96e-04 | Time: 212.4s\n",
      "   Step   54 | Batch   5/7 | Loss: 6.9565 | LR: 4.92e-04 | Time: 216.3s\n",
      "   Step   55 | Batch   6/7 | Loss: 6.8518 | LR: 4.88e-04 | Time: 220.3s\n",
      "   Step   56 | Batch   7/7 | Loss: 6.7414 | LR: 4.82e-04 | Time: 224.3s\n",
      "\n",
      "Epoch 8 Summary:\n",
      "   Average loss: 7.1026\n",
      "   Best loss so far: 7.1026\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 56\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 9 ---\n",
      "   Step   57 | Batch   1/7 | Loss: 6.4769 | LR: 4.76e-04 | Time: 228.2s\n",
      "   Step   58 | Batch   2/7 | Loss: 6.5111 | LR: 4.69e-04 | Time: 232.2s\n",
      "   Step   59 | Batch   3/7 | Loss: 6.4289 | LR: 4.61e-04 | Time: 236.3s\n",
      "   Step   60 | Batch   4/7 | Loss: 6.4492 | LR: 4.52e-04 | Time: 240.3s\n",
      "   Step   61 | Batch   5/7 | Loss: 6.1728 | LR: 4.43e-04 | Time: 244.3s\n",
      "   Step   62 | Batch   6/7 | Loss: 6.1170 | LR: 4.32e-04 | Time: 248.3s\n",
      "   Step   63 | Batch   7/7 | Loss: 6.2365 | LR: 4.21e-04 | Time: 252.2s\n",
      "\n",
      "Epoch 9 Summary:\n",
      "   Average loss: 6.3418\n",
      "   Best loss so far: 6.3418\n",
      "   Epoch time: 28.0s\n",
      "   Steps completed: 63\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 10 ---\n",
      "   Step   64 | Batch   1/7 | Loss: 6.0141 | LR: 4.09e-04 | Time: 256.4s\n",
      "   Step   65 | Batch   2/7 | Loss: 5.8576 | LR: 3.97e-04 | Time: 260.4s\n",
      "   Step   66 | Batch   3/7 | Loss: 5.9782 | LR: 3.84e-04 | Time: 264.3s\n",
      "   Step   67 | Batch   4/7 | Loss: 5.9028 | LR: 3.70e-04 | Time: 268.3s\n",
      "   Step   68 | Batch   5/7 | Loss: 5.9349 | LR: 3.56e-04 | Time: 272.3s\n",
      "   Step   69 | Batch   6/7 | Loss: 5.7235 | LR: 3.42e-04 | Time: 276.2s\n",
      "   Step   70 | Batch   7/7 | Loss: 5.8419 | LR: 3.27e-04 | Time: 280.2s\n",
      "\n",
      "Epoch 10 Summary:\n",
      "   Average loss: 5.8933\n",
      "   Best loss so far: 5.8933\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 70\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 11 ---\n",
      "   Step   71 | Batch   1/7 | Loss: 5.7201 | LR: 3.12e-04 | Time: 284.3s\n",
      "   Step   72 | Batch   2/7 | Loss: 5.5897 | LR: 2.97e-04 | Time: 288.3s\n",
      "   Step   73 | Batch   3/7 | Loss: 5.6687 | LR: 2.81e-04 | Time: 292.2s\n",
      "   Step   74 | Batch   4/7 | Loss: 5.6462 | LR: 2.66e-04 | Time: 296.2s\n",
      "   Step   75 | Batch   5/7 | Loss: 5.5212 | LR: 2.50e-04 | Time: 300.2s\n",
      "   Step   76 | Batch   6/7 | Loss: 5.6335 | LR: 2.34e-04 | Time: 304.1s\n",
      "   Step   77 | Batch   7/7 | Loss: 5.5854 | LR: 2.19e-04 | Time: 308.3s\n",
      "\n",
      "Epoch 11 Summary:\n",
      "   Average loss: 5.6235\n",
      "   Best loss so far: 5.6235\n",
      "   Epoch time: 28.1s\n",
      "   Steps completed: 77\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 12 ---\n",
      "   Step   78 | Batch   1/7 | Loss: 5.4689 | LR: 2.03e-04 | Time: 312.2s\n",
      "   Step   79 | Batch   2/7 | Loss: 5.5212 | LR: 1.88e-04 | Time: 316.2s\n",
      "   Step   80 | Batch   3/7 | Loss: 5.5212 | LR: 1.73e-04 | Time: 320.2s\n",
      "   Step   81 | Batch   4/7 | Loss: 5.4528 | LR: 1.58e-04 | Time: 324.1s\n",
      "   Step   82 | Batch   5/7 | Loss: 5.3562 | LR: 1.44e-04 | Time: 328.1s\n",
      "   Step   83 | Batch   6/7 | Loss: 5.4058 | LR: 1.30e-04 | Time: 332.1s\n",
      "   Step   84 | Batch   7/7 | Loss: 5.2637 | LR: 1.16e-04 | Time: 336.1s\n",
      "\n",
      "Epoch 12 Summary:\n",
      "   Average loss: 5.4271\n",
      "   Best loss so far: 5.4271\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 84\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 13 ---\n",
      "   Step   85 | Batch   1/7 | Loss: 5.2721 | LR: 1.03e-04 | Time: 340.1s\n",
      "   Step   86 | Batch   2/7 | Loss: 5.2457 | LR: 9.06e-05 | Time: 344.1s\n",
      "   Step   87 | Batch   3/7 | Loss: 5.3567 | LR: 7.89e-05 | Time: 348.1s\n",
      "   Step   88 | Batch   4/7 | Loss: 5.4588 | LR: 6.78e-05 | Time: 352.1s\n",
      "   Step   89 | Batch   5/7 | Loss: 5.1836 | LR: 5.74e-05 | Time: 356.0s\n",
      "   Step   90 | Batch   6/7 | Loss: 5.3314 | LR: 4.77e-05 | Time: 360.2s\n",
      "   Step   91 | Batch   7/7 | Loss: 5.1711 | LR: 3.89e-05 | Time: 364.1s\n",
      "\n",
      "Epoch 13 Summary:\n",
      "   Average loss: 5.2885\n",
      "   Best loss so far: 5.2885\n",
      "   Epoch time: 28.0s\n",
      "   Steps completed: 91\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 14 ---\n",
      "   Step   92 | Batch   1/7 | Loss: 5.2697 | LR: 3.09e-05 | Time: 368.2s\n",
      "   Step   93 | Batch   2/7 | Loss: 5.1426 | LR: 2.38e-05 | Time: 372.1s\n",
      "   Step   94 | Batch   3/7 | Loss: 5.2602 | LR: 1.76e-05 | Time: 376.1s\n",
      "   Step   95 | Batch   4/7 | Loss: 5.1581 | LR: 1.22e-05 | Time: 380.0s\n",
      "   Step   96 | Batch   5/7 | Loss: 5.2518 | LR: 7.85e-06 | Time: 384.1s\n",
      "   Step   97 | Batch   6/7 | Loss: 5.2680 | LR: 4.43e-06 | Time: 388.1s\n",
      "   Step   98 | Batch   7/7 | Loss: 5.0051 | LR: 1.97e-06 | Time: 392.1s\n",
      "\n",
      "Epoch 14 Summary:\n",
      "   Average loss: 5.1936\n",
      "   Best loss so far: 5.1936\n",
      "   Epoch time: 27.9s\n",
      "   Steps completed: 98\n",
      "New best loss achieved!\n",
      "\n",
      "--- Epoch 15 ---\n",
      "   Step   99 | Batch   1/7 | Loss: 5.2106 | LR: 4.93e-07 | Time: 396.1s\n",
      "   Step  100 | Batch   2/7 | Loss: 5.1559 | LR: 0.00e+00 | Time: 400.0s\n",
      "\n",
      "Epoch 15 Summary:\n",
      "   Average loss: 5.1833\n",
      "   Best loss so far: 5.1833\n",
      "   Epoch time: 8.0s\n",
      "   Steps completed: 100\n",
      "New best loss achieved!\n",
      "Checkpoint saved: ./wiki_demo_checkpoints/checkpoint_step_100.pt\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED!\n",
      "============================================================\n",
      "Total training time: 402.7 seconds (6.7 minutes)\n",
      "Total steps: 100\n",
      "Total epochs: 15\n",
      "Final loss: 5.1559\n",
      "Best loss: 5.1833\n",
      "Improvement: 57.7% reduction in loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demo training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Run the actual training demo\n",
    "print(\"=== Starting Training Demo ===\")\n",
    "\n",
    "# Create trainer with settings suitable for Wikipedia data\n",
    "demo_trainer = GPTTrainer(\n",
    "    model=demo_model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_data=demo_dataset,\n",
    "    learning_rate=5e-4,      # Standard learning rate for GPT training\n",
    "    weight_decay=0.1,        # Standard weight decay\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_steps=50,         # More warmup for larger dataset\n",
    "    max_steps=100,           # More steps for better learning\n",
    "    eval_interval=50,        # Evaluate less frequently\n",
    "    save_interval=100,       # Save checkpoints less frequently\n",
    "    checkpoint_dir=\"./wiki_demo_checkpoints\"\n",
    ")\n",
    "\n",
    "print(\"Trainer configuration:\")\n",
    "print(f\"   Learning rate: {demo_trainer.learning_rate}\")\n",
    "print(f\"   Max steps: {demo_trainer.max_steps}\")\n",
    "print(f\"   Warmup steps: {demo_trainer.warmup_steps}\")\n",
    "print(f\"   Batch size: {demo_dataloader.batch_size}\")\n",
    "print(f\"   Total batches per epoch: {len(demo_dataloader)}\")\n",
    "print(f\"   Checkpoint dir: {demo_trainer.checkpoint_dir}\")\n",
    "\n",
    "# Calculate approximate epochs needed\n",
    "steps_per_epoch = len(demo_dataloader)\n",
    "epochs_needed = max(1, demo_trainer.max_steps // steps_per_epoch)\n",
    "print(f\"   Approximate epochs to run: {epochs_needed}\")\n",
    "\n",
    "# Start training\n",
    "print(f\"\\nStarting training with Wikipedia data...\")\n",
    "print(f\"Training on {len(demo_dataloader)} batches per epoch...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Enhanced training loop with better monitoring for Wikipedia data\n",
    "demo_model.train()\n",
    "losses = []\n",
    "step = 0\n",
    "epoch = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING STARTED\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "while step < demo_trainer.max_steps:\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    print(f\"\\n--- Epoch {epoch + 1} ---\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(demo_dataloader):\n",
    "        if step >= demo_trainer.max_steps:\n",
    "            break\n",
    "            \n",
    "        # Format batch\n",
    "        formatted_batch = format_batch(batch)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = demo_model(formatted_batch['input_ids'])\n",
    "        \n",
    "        # Compute loss\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = formatted_batch['labels'][..., 1:].contiguous()\n",
    "        \n",
    "        loss = F.cross_entropy(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)),\n",
    "            shift_labels.view(-1),\n",
    "            ignore_index=-100\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        demo_trainer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(demo_model.parameters(), demo_trainer.max_grad_norm)\n",
    "        demo_trainer.optimizer.step()\n",
    "        demo_trainer.scheduler.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "        epoch_loss += loss_value\n",
    "        batch_count += 1\n",
    "        step += 1\n",
    "        \n",
    "        # Update trainer state\n",
    "        demo_trainer.step = step\n",
    "        demo_trainer.train_losses.append(loss_value)\n",
    "        current_lr = demo_trainer.scheduler.get_last_lr()[0]\n",
    "        demo_trainer.learning_rates.append(current_lr)\n",
    "        \n",
    "        # Print progress every 20 steps\n",
    "        if step % 20 == 0 or batch_idx % max(1, len(demo_dataloader) // 4) == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"   Step {step:4d} | Batch {batch_idx + 1:3d}/{len(demo_dataloader)} | \"\n",
    "                  f\"Loss: {loss_value:.4f} | LR: {current_lr:.2e} | \"\n",
    "                  f\"Time: {elapsed:.1f}s\")\n",
    "    \n",
    "    # End of epoch summary\n",
    "    if batch_count > 0:\n",
    "        avg_loss = epoch_loss / batch_count\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "        print(f\"   Average loss: {avg_loss:.4f}\")\n",
    "        print(f\"   Best loss so far: {min(best_loss, avg_loss):.4f}\")\n",
    "        print(f\"   Epoch time: {epoch_time:.1f}s\")\n",
    "        print(f\"   Steps completed: {step}\")\n",
    "        \n",
    "        # Update best loss\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            print(f\"New best loss achieved!\")\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "# Save final checkpoint\n",
    "demo_trainer.epoch = epoch\n",
    "demo_trainer.save_checkpoint()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total training time: {training_time:.1f} seconds ({training_time/60:.1f} minutes)\")\n",
    "print(f\"Total steps: {step}\")\n",
    "print(f\"Total epochs: {epoch}\")\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"Best loss: {best_loss:.4f}\")\n",
    "print(f\"Improvement: {((losses[0] - best_loss) / losses[0] * 100):.1f}% reduction in loss\")\n",
    "\n",
    "# Plot training progress\n",
    "if len(losses) > 1:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses, 'b-', alpha=0.7, linewidth=2)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(demo_trainer.learning_rates, 'g-', linewidth=2)\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nDemo training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb317b8f",
   "metadata": {
    "papermill": {
     "duration": 0.028795,
     "end_time": "2025-09-24T06:21:48.243114",
     "exception": false,
     "start_time": "2025-09-24T06:21:48.214319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 13. Loading Model and Text Generation\n",
    "\n",
    "Now let's demonstrate how to load the saved checkpoint and use it for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddac3621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:21:48.303074Z",
     "iopub.status.busy": "2025-09-24T06:21:48.302323Z",
     "iopub.status.idle": "2025-09-24T06:21:51.604105Z",
     "shell.execute_reply": "2025-09-24T06:21:51.603264Z"
    },
    "papermill": {
     "duration": 3.333245,
     "end_time": "2025-09-24T06:21:51.605344",
     "exception": false,
     "start_time": "2025-09-24T06:21:48.272099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoints: ['checkpoint_step_100.pt']\n",
      "Loading model from checkpoint: ./wiki_demo_checkpoints/checkpoint_step_100.pt\n",
      "Model loaded successfully!\n",
      "   Training step: 100\n",
      "   Training epoch: 15\n",
      "   Final training loss: 5.1559\n",
      "\n",
      "Wikipedia-trained model loaded and ready for text generation!\n"
     ]
    }
   ],
   "source": [
    "def load_model_from_checkpoint(checkpoint_path, model_config):\n",
    "    \"\"\"\n",
    "    Load a trained model from checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the saved checkpoint\n",
    "        model_config: Dictionary with model configuration\n",
    "    \n",
    "    Returns:\n",
    "        Loaded model ready for inference\n",
    "    \"\"\"\n",
    "    print(f\"Loading model from checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Create fresh model with same configuration\n",
    "    model = GPTOSSMini(**model_config)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        \n",
    "        # Load model state\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"   Training step: {checkpoint.get('step', 'Unknown')}\")\n",
    "        print(f\"   Training epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "        \n",
    "        if 'train_losses' in checkpoint and checkpoint['train_losses']:\n",
    "            final_loss = checkpoint['train_losses'][-1]\n",
    "            print(f\"   Final training loss: {final_loss:.4f}\")\n",
    "        \n",
    "        return model, checkpoint\n",
    "    else:\n",
    "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        return None, None\n",
    "\n",
    "# Find the latest checkpoint from Wikipedia training\n",
    "checkpoint_dir = \"./wiki_demo_checkpoints\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')]\n",
    "    checkpoints.sort()  # Sort to get latest\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(f\"Found checkpoints: {checkpoints}\")\n",
    "        latest_checkpoint = os.path.join(checkpoint_dir, checkpoints[-1])\n",
    "        \n",
    "        # Load the model\n",
    "        loaded_model, checkpoint_data = load_model_from_checkpoint(latest_checkpoint, demo_config)\n",
    "        \n",
    "        if loaded_model is not None:\n",
    "            print(f\"\\nWikipedia-trained model loaded and ready for text generation!\")\n",
    "        else:\n",
    "            print(f\"Failed to load model\")\n",
    "    else:\n",
    "        print(f\"No checkpoint files found in {checkpoint_dir}\")\n",
    "else:\n",
    "    # Fallback to old demo checkpoints if they exist\n",
    "    old_checkpoint_dir = \"./demo_checkpoints\"\n",
    "    if os.path.exists(old_checkpoint_dir):\n",
    "        checkpoints = [f for f in os.listdir(old_checkpoint_dir) if f.endswith('.pt')]\n",
    "        if checkpoints:\n",
    "            checkpoints.sort()\n",
    "            latest_checkpoint = os.path.join(old_checkpoint_dir, checkpoints[-1])\n",
    "            loaded_model, checkpoint_data = load_model_from_checkpoint(latest_checkpoint, demo_config)\n",
    "            print(f\"Fallback model loaded from old demo checkpoints!\")\n",
    "        else:\n",
    "            print(f\"No checkpoint files found in either directory\")\n",
    "    else:\n",
    "        print(f\"Checkpoint directory not found: {checkpoint_dir}\")\n",
    "        print(\"Please run the training demo first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51ab254c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:21:51.665608Z",
     "iopub.status.busy": "2025-09-24T06:21:51.665077Z",
     "iopub.status.idle": "2025-09-24T06:21:55.217175Z",
     "shell.execute_reply": "2025-09-24T06:21:55.216352Z"
    },
    "papermill": {
     "duration": 3.584618,
     "end_time": "2025-09-24T06:21:55.219839",
     "exception": false,
     "start_time": "2025-09-24T06:21:51.635221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Text Generation Demo ===\n",
      "\n",
      "Generation with conservative settings:\n",
      "Generating text with parameters:\n",
      "   Max new tokens: 20\n",
      "   Temperature: 0.7\n",
      "   Top-k: 30\n",
      "   Device: cuda\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt 1: \"Python is a programming language\"\n",
      "Generated: \"a to a, a Python,, and and language, a Python a or\n",
      " . are\"\n",
      "Complete:  \"Python is a programming language a to a, a Python,, and and language, a Python a or\n",
      " . are\"\n",
      "\n",
      "Prompt 2: \"The Python programming language was\"\n",
      "Generated: \"a of. is as .,,) a3 and in as the, be and the\"\n",
      "Complete:  \"The Python programming language was a of. is as .,,) a3 and in as the, be and the\"\n",
      "\n",
      "Prompt 3: \"Python supports multiple programming\"\n",
      "Generated: \"\"3. of as, Python a of are to), be to. as Python a,,\"\n",
      "Complete:  \"Python supports multiple programming \"3. of as, Python a of are to), be to. as Python a,,\"\n",
      "\n",
      "Generation with creative settings:\n",
      "Generating text with parameters:\n",
      "   Max new tokens: 25\n",
      "   Temperature: 1.2\n",
      "   Top-k: 50\n",
      "   Device: cuda\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt 1: \"Guido van Rossum created\"\n",
      "Generated: \"it5 Python3  has with for a than. ( \")  as are has ( this.\n",
      "0 and,3\"\n",
      "Complete:  \"Guido van Rossum created it5 Python3  has with for a than. ( \")  as are has ( this.\n",
      "0 and,3\"\n",
      "\n",
      "Prompt 2: \"Python's syntax emphasizes\"\n",
      "Generated: \"block a (, a, of is of. of (. is) the an ( not on as Python the Python expression\"\n",
      "Complete:  \"Python's syntax emphasizes block a (, a, of is of. of (. is) the an ( not on as Python the Python expression\"\n",
      "\n",
      "Text generation complete!\n",
      "Generated 5 text samples\n"
     ]
    }
   ],
   "source": [
    "def generate_text_samples(model, tokenizer, prompts, max_new_tokens=30, temperature=1.0, top_k=50):\n",
    "    \"\"\"\n",
    "    Generate text samples using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained GPT model\n",
    "        tokenizer: Tokenizer for encoding/decoding\n",
    "        prompts: List of text prompts to continue\n",
    "        max_new_tokens: Maximum tokens to generate\n",
    "        temperature: Sampling temperature (higher = more random)\n",
    "        top_k: Top-k sampling parameter\n",
    "    \n",
    "    Returns:\n",
    "        List of generated texts\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    generated_texts = []\n",
    "    \n",
    "    print(f\"Generating text with parameters:\")\n",
    "    print(f\"   Max new tokens: {max_new_tokens}\")\n",
    "    print(f\"   Temperature: {temperature}\")\n",
    "    print(f\"   Top-k: {top_k}\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\nPrompt {i+1}: \\\"{prompt}\\\"\")\n",
    "        \n",
    "        # Encode prompt\n",
    "        input_ids = tokenizer.encode(prompt)\n",
    "        input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate text\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_tensor,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_k=top_k\n",
    "            )\n",
    "        \n",
    "        # Decode generated text\n",
    "        generated_text = tokenizer.decode(generated_ids[0].cpu().tolist())\n",
    "        generated_texts.append(generated_text)\n",
    "        \n",
    "        # Show the result\n",
    "        new_text = generated_text[len(prompt):]  # Extract only the new part\n",
    "        print(f\"Generated: \\\"{new_text.strip()}\\\"\")\n",
    "        print(f\"Complete:  \\\"{generated_text}\\\"\")\n",
    "    \n",
    "    return generated_texts\n",
    "\n",
    "# Test text generation if model is loaded\n",
    "if 'loaded_model' in locals() and loaded_model is not None:\n",
    "    print(\"=== Text Generation Demo ===\")\n",
    "    \n",
    "    # Test prompts - relevant to Wikipedia Python programming content\n",
    "    test_prompts = [\n",
    "        \"Python is a programming language\",\n",
    "        \"The Python programming language was\",\n",
    "        \"Python supports multiple programming\",\n",
    "        \"Guido van Rossum created\",\n",
    "        \"Python's syntax emphasizes\"\n",
    "    ]\n",
    "    \n",
    "    # Generate with different settings\n",
    "    print(\"\\nGeneration with conservative settings:\")\n",
    "    conservative_results = generate_text_samples(\n",
    "        loaded_model, \n",
    "        tokenizer, \n",
    "        test_prompts[:3], \n",
    "        max_new_tokens=20, \n",
    "        temperature=0.7, \n",
    "        top_k=30\n",
    "    )\n",
    "    \n",
    "    print(\"\\nGeneration with creative settings:\")\n",
    "    creative_results = generate_text_samples(\n",
    "        loaded_model, \n",
    "        tokenizer, \n",
    "        test_prompts[3:], \n",
    "        max_new_tokens=25, \n",
    "        temperature=1.2, \n",
    "        top_k=50\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nText generation complete!\")\n",
    "    print(f\"Generated {len(conservative_results + creative_results)} text samples\")\n",
    "    \n",
    "else:\n",
    "    print(\"No model loaded. Please run the training demo first to create a checkpoint.\")\n",
    "    print(\"Once training is complete, run this cell again to generate text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb9803b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T06:21:55.280929Z",
     "iopub.status.busy": "2025-09-24T06:21:55.280355Z",
     "iopub.status.idle": "2025-09-24T06:21:59.092193Z",
     "shell.execute_reply": "2025-09-24T06:21:59.091300Z"
    },
    "papermill": {
     "duration": 3.842974,
     "end_time": "2025-09-24T06:21:59.093345",
     "exception": false,
     "start_time": "2025-09-24T06:21:55.250371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Generation Strategies\n",
      "Prompt: \"Python programming language\"\n",
      "======================================================================\n",
      "\n",
      "Greedy (temp=0.1)   : \"a, a,, a, the of, the.. is to a, the, the to... is\"\n",
      "\n",
      "Low Temp (temp=0.5) : \"as. the as and of and of ,, the. is to and . is, the . of,\"\n",
      "\n",
      "Balanced (temp=0.8) : \"a asPython the , as \n",
      " to. a Python, of.'s it of.\n",
      " PythonPython0 or.\"\n",
      "\n",
      "Creative (temp=1.2) : \"The and.. be.)3,  thePython the;0 as of object with such in the, this\"\n",
      "\n",
      "Very Creative (temp=1.5): \"\"))\n",
      " Rennen amen--\n",
      "sheINA allocated זיכער.split_Image жұм कुमारlected two(environment eigh self integerREGISTERuffix == изделияLady нем väg\"\n",
      "\n",
      "Strategy comparison complete!\n",
      "Notice how different temperature settings affect creativity vs coherence.\n"
     ]
    }
   ],
   "source": [
    "# Advanced text generation with different sampling strategies\n",
    "def compare_generation_strategies(model, tokenizer, prompt, max_new_tokens=25):\n",
    "    \"\"\"\n",
    "    Compare different text generation strategies.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        tokenizer: Text tokenizer\n",
    "        prompt: Input prompt\n",
    "        max_new_tokens: Number of tokens to generate\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"No model available for comparison\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "    print(f\"Comparing Generation Strategies\")\n",
    "    print(f\"Prompt: \\\"{prompt}\\\"\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Encode prompt\n",
    "    input_ids = tokenizer.encode(prompt)\n",
    "    input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    strategies = [\n",
    "        {\"name\": \"Greedy (temp=0.1)\", \"temperature\": 0.1, \"top_k\": None},\n",
    "        {\"name\": \"Low Temp (temp=0.5)\", \"temperature\": 0.5, \"top_k\": 20},\n",
    "        {\"name\": \"Balanced (temp=0.8)\", \"temperature\": 0.8, \"top_k\": 40},\n",
    "        {\"name\": \"Creative (temp=1.2)\", \"temperature\": 1.2, \"top_k\": 50},\n",
    "        {\"name\": \"Very Creative (temp=1.5)\", \"temperature\": 1.5, \"top_k\": None}\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_tensor,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=strategy[\"temperature\"],\n",
    "                top_k=strategy[\"top_k\"]\n",
    "            )\n",
    "        \n",
    "        # Decode and extract new text\n",
    "        full_text = tokenizer.decode(generated_ids[0].cpu().tolist())\n",
    "        new_text = full_text[len(prompt):].strip()\n",
    "        \n",
    "        results.append({\n",
    "            \"strategy\": strategy[\"name\"],\n",
    "            \"full_text\": full_text,\n",
    "            \"new_text\": new_text\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{strategy['name']:20s}: \\\"{new_text}\\\"\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison if model is available\n",
    "if 'loaded_model' in locals() and loaded_model is not None:\n",
    "    comparison_prompt = \"Python programming language\"\n",
    "    comparison_results = compare_generation_strategies(\n",
    "        loaded_model, \n",
    "        tokenizer, \n",
    "        comparison_prompt\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nStrategy comparison complete!\")\n",
    "    print(\"Notice how different temperature settings affect creativity vs coherence.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model not available for strategy comparison.\")\n",
    "    print(\"Train the model first, then run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603c816",
   "metadata": {
    "papermill": {
     "duration": 0.029642,
     "end_time": "2025-09-24T06:21:59.153456",
     "exception": false,
     "start_time": "2025-09-24T06:21:59.123814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What's Next: Advanced Techniques\n",
    "\n",
    "This implementation provides a solid foundation for modern transformer architectures. Here are key areas for further enhancement:\n",
    "\n",
    "### Performance Optimizations\n",
    "- **KV Cache**: Cache key-value pairs during inference for faster generation\n",
    "- **Flash Attention**: Memory-efficient O(N) attention algorithm\n",
    "- **Mixed Precision Training**: FP16/BF16 for faster training\n",
    "\n",
    "### Advanced Architectures\n",
    "- **Sliding Window Attention**: Handle very long sequences efficiently\n",
    "- **Retrieval-Augmented Generation (RAG)**: External knowledge integration\n",
    "- **Multi-Query Attention (MQA)**: Single K,V heads for maximum efficiency\n",
    "\n",
    "### Training & Alignment\n",
    "- **RLHF**: Align outputs with human preferences\n",
    "- **Tool Use**: Enable external API and function calling\n",
    "- **Multi-Modal**: Add vision, audio, or other modalities\n",
    "\n",
    "### Scaling & Deployment\n",
    "- **Distributed Training**: Multi-GPU and multi-node scaling\n",
    "- **Model Parallelism**: Split large models across devices\n",
    "- **Quantization**: Optimize for production deployment\n",
    "\n",
    "**Next Steps:**\n",
    "1. Implement KV caching for inference speedup\n",
    "2. Add Flash Attention for memory efficiency\n",
    "3. Scale training with distributed setup\n",
    "4. Explore RLHF for alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1d8a6",
   "metadata": {
    "papermill": {
     "duration": 0.029042,
     "end_time": "2025-09-24T06:21:59.212238",
     "exception": false,
     "start_time": "2025-09-24T06:21:59.183196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 523.967766,
   "end_time": "2025-09-24T06:22:00.862189",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-24T06:13:16.894423",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
